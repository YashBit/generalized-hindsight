No personal conf_private.py found.
doodad not detected
2022-04-10 11:56:30.630872 EDT | Variant:
2022-04-10 11:56:30.631183 EDT | {
  "seed": 0,
  "algorithm": "SAC",
  "env_name": "AntEnv",
  "algo_kwargs": {
    "batch_size": 256,
    "num_epochs": 1000,
    "num_eval_steps_per_epoch": 25000,
    "num_expl_steps_per_train_loop": 1000,
    "num_trains_per_train_loop": 100,
    "min_num_steps_before_training": 1000,
    "max_path_length": 1000,
    "num_train_loops_per_epoch": 1
  },
  "trainer_kwargs": {
    "discount": 0.99,
    "soft_target_tau": 0.005,
    "target_update_period": 1,
    "policy_lr": 0.003,
    "qf_lr": 0.003,
    "reward_scale": 1,
    "use_automatic_entropy_tuning": true
  },
  "replay_buffer_kwargs": {
    "max_replay_buffer_size": 1000000,
    "latent_dim": 1,
    "approx_irl": true,
    "plot": false
  },
  "relabeler_kwargs": {
    "relabel": true,
    "use_adv": true,
    "n_sampled_latents": 100,
    "n_to_take": 1,
    "cache": true
  },
  "qf_kwargs": {
    "hidden_sizes": [
      256,
      256
    ],
    "latent_shape_multiplier": 1,
    "latent_to_all_layers": false
  },
  "policy_kwargs": {
    "hidden_sizes": [
      256,
      256
    ],
    "latent_shape_multiplier": 1,
    "latent_to_all_layers": false
  },
  "path_collector_kwargs": {
    "save_videos": false
  },
  "use_advantages": true,
  "proper_advantages": true,
  "plot": false,
  "test": false,
  "gpu": 0,
  "mode": "here_no_doodad",
  "local_docker": false,
  "insert_time": false,
  "latent_shape_multiplier": 1,
  "env_kwargs": {
    "use_xy": false,
    "contact_forces": false
  },
  "gpu_id": 0
}
AntEnv
Self.relabel is : True
Latents is : <class 'numpy.ndarray'>, its shape is : (6, 1), print for latent : [[-1.48]
 [-1.16]
 [-1.55]
 [-1.14]
 [-1.47]
 [-1.14]]
obs is : <class 'numpy.ndarray'>, its shape is : (27,), print for obs : [0.74 0.99 -0.06 -0.04 0.07 0.08 -0.04 -0.02 -0.01 0.08 0.06 -0.03 -0.07
 0.14 0.05 0.02 0.08 0.05 0.04 -0.23 -0.07 -0.01 -0.18 0.12 -0.12 0.03
 0.02]
AFTER RESHAPE
latent is : <class 'torch.Tensor'>, its shape is : torch.Size([6, 1]), print for latent : tensor([[-1.4793],
        [-1.1597],
        [-1.5501],
        [-1.1436],
        [-1.4741],
        [-1.1400]], device='cuda:0')
obs is : <class 'torch.Tensor'>, its shape is : torch.Size([6, 27]), print for obs : tensor([[ 0.7411,  0.9945, -0.0627, -0.0415,  0.0733,  0.0762, -0.0437, -0.0233,
         -0.0074,  0.0811,  0.0617, -0.0315, -0.0716,  0.1433,  0.0480,  0.0195,
          0.0785,  0.0516,  0.0361, -0.2295, -0.0711, -0.0123, -0.1782,  0.1156,
         -0.1162,  0.0290,  0.0203],
        [ 0.7411,  0.9945, -0.0627, -0.0415,  0.0733,  0.0762, -0.0437, -0.0233,
         -0.0074,  0.0811,  0.0617, -0.0315, -0.0716,  0.1433,  0.0480,  0.0195,
          0.0785,  0.0516,  0.0361, -0.2295, -0.0711, -0.0123, -0.1782,  0.1156,
         -0.1162,  0.0290,  0.0203],
        [ 0.7411,  0.9945, -0.0627, -0.0415,  0.0733,  0.0762, -0.0437, -0.0233,
         -0.0074,  0.0811,  0.0617, -0.0315, -0.0716,  0.1433,  0.0480,  0.0195,
          0.0785,  0.0516,  0.0361, -0.2295, -0.0711, -0.0123, -0.1782,  0.1156,
         -0.1162,  0.0290,  0.0203],
        [ 0.7411,  0.9945, -0.0627, -0.0415,  0.0733,  0.0762, -0.0437, -0.0233,
         -0.0074,  0.0811,  0.0617, -0.0315, -0.0716,  0.1433,  0.0480,  0.0195,
          0.0785,  0.0516,  0.0361, -0.2295, -0.0711, -0.0123, -0.1782,  0.1156,
         -0.1162,  0.0290,  0.0203],
        [ 0.7411,  0.9945, -0.0627, -0.0415,  0.0733,  0.0762, -0.0437, -0.0233,
         -0.0074,  0.0811,  0.0617, -0.0315, -0.0716,  0.1433,  0.0480,  0.0195,
          0.0785,  0.0516,  0.0361, -0.2295, -0.0711, -0.0123, -0.1782,  0.1156,
         -0.1162,  0.0290,  0.0203],
        [ 0.7411,  0.9945, -0.0627, -0.0415,  0.0733,  0.0762, -0.0437, -0.0233,
         -0.0074,  0.0811,  0.0617, -0.0315, -0.0716,  0.1433,  0.0480,  0.0195,
          0.0785,  0.0516,  0.0361, -0.2295, -0.0711, -0.0123, -0.1782,  0.1156,
         -0.1162,  0.0290,  0.0203]], device='cuda:0')
Latents is : <class 'numpy.ndarray'>, its shape is : (11, 1), print for latent : [[1.14]
 [1.05]
 [1.07]
 [-1.82]
 [-1.83]
 [-1.61]
 [0.98]
 [1.50]
 [1.05]
 [1.36]
 [1.35]]
obs is : <class 'numpy.ndarray'>, its shape is : (27,), print for obs : [0.66 0.99 0.00 -0.09 -0.08 0.06 -0.04 0.01 -0.09 -0.09 -0.09 -0.03 0.05
 0.07 -0.12 0.04 0.02 0.04 0.11 0.09 -0.13 -0.03 -0.08 0.09 0.23 0.10
 -0.14]
AFTER RESHAPE
latent is : <class 'torch.Tensor'>, its shape is : torch.Size([11, 1]), print for latent : tensor([[ 1.1424],
        [ 1.0478],
        [ 1.0721],
        [-1.8197],
        [-1.8292],
        [-1.6058],
        [ 0.9822],
        [ 1.5033],
        [ 1.0519],
        [ 1.3592],
        [ 1.3521]], device='cuda:0')
obs is : <class 'torch.Tensor'>, its shape is : torch.Size([11, 27]), print for obs : tensor([[ 0.6596,  0.9931,  0.0045, -0.0882, -0.0765,  0.0594, -0.0410,  0.0073,
         -0.0886, -0.0918, -0.0919, -0.0341,  0.0492,  0.0704, -0.1179,  0.0351,
          0.0194,  0.0387,  0.1122,  0.0945, -0.1272, -0.0342, -0.0794,  0.0889,
          0.2273,  0.1047, -0.1400],
        [ 0.6596,  0.9931,  0.0045, -0.0882, -0.0765,  0.0594, -0.0410,  0.0073,
         -0.0886, -0.0918, -0.0919, -0.0341,  0.0492,  0.0704, -0.1179,  0.0351,
          0.0194,  0.0387,  0.1122,  0.0945, -0.1272, -0.0342, -0.0794,  0.0889,
          0.2273,  0.1047, -0.1400],
        [ 0.6596,  0.9931,  0.0045, -0.0882, -0.0765,  0.0594, -0.0410,  0.0073,
         -0.0886, -0.0918, -0.0919, -0.0341,  0.0492,  0.0704, -0.1179,  0.0351,
          0.0194,  0.0387,  0.1122,  0.0945, -0.1272, -0.0342, -0.0794,  0.0889,
          0.2273,  0.1047, -0.1400],
        [ 0.6596,  0.9931,  0.0045, -0.0882, -0.0765,  0.0594, -0.0410,  0.0073,
         -0.0886, -0.0918, -0.0919, -0.0341,  0.0492,  0.0704, -0.1179,  0.0351,
          0.0194,  0.0387,  0.1122,  0.0945, -0.1272, -0.0342, -0.0794,  0.0889,
          0.2273,  0.1047, -0.1400],
        [ 0.6596,  0.9931,  0.0045, -0.0882, -0.0765,  0.0594, -0.0410,  0.0073,
         -0.0886, -0.0918, -0.0919, -0.0341,  0.0492,  0.0704, -0.1179,  0.0351,
          0.0194,  0.0387,  0.1122,  0.0945, -0.1272, -0.0342, -0.0794,  0.0889,
          0.2273,  0.1047, -0.1400],
        [ 0.6596,  0.9931,  0.0045, -0.0882, -0.0765,  0.0594, -0.0410,  0.0073,
         -0.0886, -0.0918, -0.0919, -0.0341,  0.0492,  0.0704, -0.1179,  0.0351,
          0.0194,  0.0387,  0.1122,  0.0945, -0.1272, -0.0342, -0.0794,  0.0889,
          0.2273,  0.1047, -0.1400],
        [ 0.6596,  0.9931,  0.0045, -0.0882, -0.0765,  0.0594, -0.0410,  0.0073,
         -0.0886, -0.0918, -0.0919, -0.0341,  0.0492,  0.0704, -0.1179,  0.0351,
          0.0194,  0.0387,  0.1122,  0.0945, -0.1272, -0.0342, -0.0794,  0.0889,
          0.2273,  0.1047, -0.1400],
        [ 0.6596,  0.9931,  0.0045, -0.0882, -0.0765,  0.0594, -0.0410,  0.0073,
         -0.0886, -0.0918, -0.0919, -0.0341,  0.0492,  0.0704, -0.1179,  0.0351,
          0.0194,  0.0387,  0.1122,  0.0945, -0.1272, -0.0342, -0.0794,  0.0889,
          0.2273,  0.1047, -0.1400],
        [ 0.6596,  0.9931,  0.0045, -0.0882, -0.0765,  0.0594, -0.0410,  0.0073,
         -0.0886, -0.0918, -0.0919, -0.0341,  0.0492,  0.0704, -0.1179,  0.0351,
          0.0194,  0.0387,  0.1122,  0.0945, -0.1272, -0.0342, -0.0794,  0.0889,
          0.2273,  0.1047, -0.1400],
        [ 0.6596,  0.9931,  0.0045, -0.0882, -0.0765,  0.0594, -0.0410,  0.0073,
         -0.0886, -0.0918, -0.0919, -0.0341,  0.0492,  0.0704, -0.1179,  0.0351,
          0.0194,  0.0387,  0.1122,  0.0945, -0.1272, -0.0342, -0.0794,  0.0889,
          0.2273,  0.1047, -0.1400],
        [ 0.6596,  0.9931,  0.0045, -0.0882, -0.0765,  0.0594, -0.0410,  0.0073,
         -0.0886, -0.0918, -0.0919, -0.0341,  0.0492,  0.0704, -0.1179,  0.0351,
          0.0194,  0.0387,  0.1122,  0.0945, -0.1272, -0.0342, -0.0794,  0.0889,
          0.2273,  0.1047, -0.1400]], device='cuda:0')
Latents is : <class 'numpy.ndarray'>, its shape is : (3, 1), print for latent : [[-2.33]
 [-2.27]
 [-2.31]]
obs is : <class 'numpy.ndarray'>, its shape is : (27,), print for obs : [0.68 1.00 -0.03 -0.07 -0.03 0.04 0.04 0.10 -0.07 0.02 -0.06 -0.05 0.08
 0.11 -0.10 0.12 -0.10 0.06 0.04 0.07 0.02 0.04 0.18 0.11 0.03 -0.11 0.06]
AFTER RESHAPE
latent is : <class 'torch.Tensor'>, its shape is : torch.Size([3, 1]), print for latent : tensor([[-2.3315],
        [-2.2734],
        [-2.3135]], device='cuda:0')
obs is : <class 'torch.Tensor'>, its shape is : torch.Size([3, 27]), print for obs : tensor([[ 0.6755,  0.9964, -0.0301, -0.0730, -0.0317,  0.0419,  0.0391,  0.0980,
         -0.0713,  0.0220, -0.0630, -0.0516,  0.0798,  0.1092, -0.1025,  0.1212,
         -0.0985,  0.0589,  0.0442,  0.0729,  0.0187,  0.0444,  0.1838,  0.1119,
          0.0350, -0.1127,  0.0564],
        [ 0.6755,  0.9964, -0.0301, -0.0730, -0.0317,  0.0419,  0.0391,  0.0980,
         -0.0713,  0.0220, -0.0630, -0.0516,  0.0798,  0.1092, -0.1025,  0.1212,
         -0.0985,  0.0589,  0.0442,  0.0729,  0.0187,  0.0444,  0.1838,  0.1119,
          0.0350, -0.1127,  0.0564],
        [ 0.6755,  0.9964, -0.0301, -0.0730, -0.0317,  0.0419,  0.0391,  0.0980,
         -0.0713,  0.0220, -0.0630, -0.0516,  0.0798,  0.1092, -0.1025,  0.1212,
         -0.0985,  0.0589,  0.0442,  0.0729,  0.0187,  0.0444,  0.1838,  0.1119,
          0.0350, -0.1127,  0.0564]], device='cuda:0')
Latents is : <class 'numpy.ndarray'>, its shape is : (6, 1), print for latent : [[2.67]
 [2.32]
 [2.79]
 [2.79]
 [2.70]
 [2.46]]
obs is : <class 'numpy.ndarray'>, its shape is : (27,), print for obs : [0.67 1.00 -0.08 -0.00 0.02 0.01 0.09 0.08 0.06 -0.09 0.08 -0.05 0.06 0.09
 0.11 0.08 -0.20 -0.05 0.09 -0.12 0.00 0.09 -0.06 0.04 0.08 -0.14 0.10]
AFTER RESHAPE
latent is : <class 'torch.Tensor'>, its shape is : torch.Size([6, 1]), print for latent : tensor([[2.6741],
        [2.3249],
        [2.7939],
        [2.7882],
        [2.6973],
        [2.4616]], device='cuda:0')
obs is : <class 'torch.Tensor'>, its shape is : torch.Size([6, 27]), print for obs : tensor([[ 0.6718,  0.9962, -0.0840, -0.0037,  0.0204,  0.0146,  0.0870,  0.0819,
          0.0628, -0.0884,  0.0821, -0.0538,  0.0583,  0.0916,  0.1051,  0.0774,
         -0.1961, -0.0488,  0.0946, -0.1212,  0.0025,  0.0885, -0.0645,  0.0377,
          0.0808, -0.1395,  0.1023],
        [ 0.6718,  0.9962, -0.0840, -0.0037,  0.0204,  0.0146,  0.0870,  0.0819,
          0.0628, -0.0884,  0.0821, -0.0538,  0.0583,  0.0916,  0.1051,  0.0774,
         -0.1961, -0.0488,  0.0946, -0.1212,  0.0025,  0.0885, -0.0645,  0.0377,
          0.0808, -0.1395,  0.1023],
        [ 0.6718,  0.9962, -0.0840, -0.0037,  0.0204,  0.0146,  0.0870,  0.0819,
          0.0628, -0.0884,  0.0821, -0.0538,  0.0583,  0.0916,  0.1051,  0.0774,
         -0.1961, -0.0488,  0.0946, -0.1212,  0.0025,  0.0885, -0.0645,  0.0377,
          0.0808, -0.1395,  0.1023],
        [ 0.6718,  0.9962, -0.0840, -0.0037,  0.0204,  0.0146,  0.0870,  0.0819,
          0.0628, -0.0884,  0.0821, -0.0538,  0.0583,  0.0916,  0.1051,  0.0774,
         -0.1961, -0.0488,  0.0946, -0.1212,  0.0025,  0.0885, -0.0645,  0.0377,
          0.0808, -0.1395,  0.1023],
        [ 0.6718,  0.9962, -0.0840, -0.0037,  0.0204,  0.0146,  0.0870,  0.0819,
          0.0628, -0.0884,  0.0821, -0.0538,  0.0583,  0.0916,  0.1051,  0.0774,
         -0.1961, -0.0488,  0.0946, -0.1212,  0.0025,  0.0885, -0.0645,  0.0377,
          0.0808, -0.1395,  0.1023],
        [ 0.6718,  0.9962, -0.0840, -0.0037,  0.0204,  0.0146,  0.0870,  0.0819,
          0.0628, -0.0884,  0.0821, -0.0538,  0.0583,  0.0916,  0.1051,  0.0774,
         -0.1961, -0.0488,  0.0946, -0.1212,  0.0025,  0.0885, -0.0645,  0.0377,
          0.0808, -0.1395,  0.1023]], device='cuda:0')
Latents is : <class 'numpy.ndarray'>, its shape is : (88, 1), print for latent : [[0.43]
 [-2.70]
 [-2.59]
 [-3.01]
 [2.09]
 [1.75]
 [3.01]
 [1.88]
 [-0.24]
 [1.76]
 [-2.40]
 [0.88]
 [-2.24]
 [0.14]
 [-0.54]
 [1.72]
 [-0.28]
 [0.43]
 [-3.02]
 [0.74]
 [0.70]
 [0.73]
 [1.14]
 [-0.88]
 [-0.40]
 [1.24]
 [-2.76]
 [1.05]
 [1.07]
 [-1.82]
 [-2.33]
 [-1.16]
 [-0.86]
 [0.44]
 [-0.39]
 [3.07]
 [-2.50]
 [-1.83]
 [-2.13]
 [0.96]
 [-0.21]
 [-2.14]
 [-2.45]
 [0.98]
 [-2.27]
 [-1.91]
 [-0.82]
 [2.02]
 [-2.53]
 [2.12]
 [-2.54]
 [2.99]
 [-0.20]
 [3.00]
 [0.66]
 [1.50]
 [-2.90]
 [-2.39]
 [-1.28]
 [-2.40]
 [-1.14]
 [-0.54]
 [-2.74]
 [1.21]
 [0.42]
 [0.15]
 [-2.55]
 [0.48]
 [-1.14]
 [1.05]
 [-2.31]
 [1.36]
 [-1.32]
 [-1.99]
 [0.54]
 [-3.02]
 [2.07]
 [-3.11]
 [1.35]
 [0.65]
 [0.28]
 [-0.48]
 [0.92]
 [-0.39]
 [2.91]
 [-0.73]
 [1.83]
 [0.18]]
obs is : <class 'numpy.ndarray'>, its shape is : (27,), print for obs : [0.82 0.99 0.06 0.09 0.07 0.07 -0.05 0.08 0.08 0.09 0.08 0.07 0.00 0.11
 -0.01 -0.02 0.06 -0.01 -0.07 -0.03 0.25 0.09 0.04 -0.11 -0.08 -0.07 0.02]
AFTER RESHAPE
latent is : <class 'torch.Tensor'>, its shape is : torch.Size([88, 1]), print for latent : tensor([[ 0.4275],
        [-2.6953],
        [-2.5941],
        [-3.0146],
        [ 2.0899],
        [ 1.7477],
        [ 3.0072],
        [ 1.8797],
        [-0.2420],
        [ 1.7626],
        [-2.3985],
        [ 0.8791],
        [-2.2409],
        [ 0.1373],
        [-0.5362],
        [ 1.7231],
        [-0.2755],
        [ 0.4300],
        [-3.0235],
        [ 0.7391],
        [ 0.7043],
        [ 0.7347],
        [ 1.1424],
        [-0.8827],
        [-0.3956],
        [ 1.2418],
        [-2.7632],
        [ 1.0478],
        [ 1.0721],
        [-1.8197],
        [-2.3315],
        [-1.1597],
        [-0.8563],
        [ 0.4411],
        [-0.3858],
        [ 3.0685],
        [-2.5004],
        [-1.8292],
        [-2.1281],
        [ 0.9620],
        [-0.2117],
        [-2.1428],
        [-2.4481],
        [ 0.9822],
        [-2.2734],
        [-1.9064],
        [-0.8248],
        [ 2.0169],
        [-2.5315],
        [ 2.1234],
        [-2.5378],
        [ 2.9937],
        [-0.1970],
        [ 2.9956],
        [ 0.6588],
        [ 1.5033],
        [-2.8954],
        [-2.3864],
        [-1.2809],
        [-2.3956],
        [-1.1436],
        [-0.5387],
        [-2.7385],
        [ 1.2093],
        [ 0.4185],
        [ 0.1461],
        [-2.5513],
        [ 0.4772],
        [-1.1400],
        [ 1.0519],
        [-2.3135],
        [ 1.3592],
        [-1.3232],
        [-1.9906],
        [ 0.5436],
        [-3.0153],
        [ 2.0668],
        [-3.1121],
        [ 1.3521],
        [ 0.6457],
        [ 0.2820],
        [-0.4797],
        [ 0.9167],
        [-0.3922],
        [ 2.9133],
        [-0.7324],
        [ 1.8330],
        [ 0.1816]], device='cuda:0')
obs is : <class 'torch.Tensor'>, its shape is : torch.Size([88, 27]), print for obs : tensor([[ 0.8178,  0.9921,  0.0579,  ..., -0.0787, -0.0741,  0.0244],
        [ 0.8178,  0.9921,  0.0579,  ..., -0.0787, -0.0741,  0.0244],
        [ 0.8178,  0.9921,  0.0579,  ..., -0.0787, -0.0741,  0.0244],
        ...,
        [ 0.8178,  0.9921,  0.0579,  ..., -0.0787, -0.0741,  0.0244],
        [ 0.8178,  0.9921,  0.0579,  ..., -0.0787, -0.0741,  0.0244],
        [ 0.8178,  0.9921,  0.0579,  ..., -0.0787, -0.0741,  0.0244]],
       device='cuda:0')
Latents is : <class 'numpy.ndarray'>, its shape is : (5, 1), print for latent : [[-1.48]
 [-1.55]
 [-1.61]
 [-1.36]
 [-1.47]]
obs is : <class 'numpy.ndarray'>, its shape is : (27,), print for obs : [0.82 1.00 -0.07 0.05 -0.02 -0.02 -0.04 0.03 -0.01 0.05 -0.03 0.04 -0.06
 -0.03 -0.03 -0.25 -0.12 0.03 -0.07 0.04 -0.01 0.21 0.05 -0.05 0.00 -0.03
 -0.18]
AFTER RESHAPE
latent is : <class 'torch.Tensor'>, its shape is : torch.Size([5, 1]), print for latent : tensor([[-1.4793],
        [-1.5501],
        [-1.6058],
        [-1.3647],
        [-1.4741]], device='cuda:0')
obs is : <class 'torch.Tensor'>, its shape is : torch.Size([5, 27]), print for obs : tensor([[ 0.8204,  0.9966, -0.0659,  0.0451, -0.0199, -0.0239, -0.0375,  0.0279,
         -0.0072,  0.0469, -0.0324,  0.0438, -0.0564, -0.0290, -0.0298, -0.2532,
         -0.1163,  0.0295, -0.0748,  0.0373, -0.0102,  0.2076,  0.0542, -0.0542,
          0.0049, -0.0288, -0.1760],
        [ 0.8204,  0.9966, -0.0659,  0.0451, -0.0199, -0.0239, -0.0375,  0.0279,
         -0.0072,  0.0469, -0.0324,  0.0438, -0.0564, -0.0290, -0.0298, -0.2532,
         -0.1163,  0.0295, -0.0748,  0.0373, -0.0102,  0.2076,  0.0542, -0.0542,
          0.0049, -0.0288, -0.1760],
        [ 0.8204,  0.9966, -0.0659,  0.0451, -0.0199, -0.0239, -0.0375,  0.0279,
         -0.0072,  0.0469, -0.0324,  0.0438, -0.0564, -0.0290, -0.0298, -0.2532,
         -0.1163,  0.0295, -0.0748,  0.0373, -0.0102,  0.2076,  0.0542, -0.0542,
          0.0049, -0.0288, -0.1760],
        [ 0.8204,  0.9966, -0.0659,  0.0451, -0.0199, -0.0239, -0.0375,  0.0279,
         -0.0072,  0.0469, -0.0324,  0.0438, -0.0564, -0.0290, -0.0298, -0.2532,
         -0.1163,  0.0295, -0.0748,  0.0373, -0.0102,  0.2076,  0.0542, -0.0542,
          0.0049, -0.0288, -0.1760],
        [ 0.8204,  0.9966, -0.0659,  0.0451, -0.0199, -0.0239, -0.0375,  0.0279,
         -0.0072,  0.0469, -0.0324,  0.0438, -0.0564, -0.0290, -0.0298, -0.2532,
         -0.1163,  0.0295, -0.0748,  0.0373, -0.0102,  0.2076,  0.0542, -0.0542,
          0.0049, -0.0288, -0.1760]], device='cuda:0')
Latents is : <class 'numpy.ndarray'>, its shape is : (68, 1), print for latent : [[0.43]
 [2.67]
 [-2.70]
 [-2.59]
 [-3.01]
 [2.09]
 [2.32]
 [3.01]
 [1.88]
 [-0.24]
 [0.88]
 [2.79]
 [-0.54]
 [-1.48]
 [-0.28]
 [0.43]
 [-3.02]
 [0.74]
 [0.70]
 [0.73]
 [2.79]
 [-0.88]
 [-0.40]
 [-2.76]
 [-1.16]
 [-0.86]
 [0.44]
 [-0.39]
 [3.07]
 [-2.50]
 [-1.55]
 [-0.21]
 [-0.82]
 [2.02]
 [-2.53]
 [2.12]
 [-2.54]
 [2.99]
 [-0.20]
 [3.00]
 [0.66]
 [-2.90]
 [-1.36]
 [-1.28]
 [-1.14]
 [-0.54]
 [-2.74]
 [0.42]
 [-1.47]
 [-2.55]
 [0.48]
 [2.70]
 [-1.14]
 [-1.32]
 [0.54]
 [-3.02]
 [2.07]
 [-3.11]
 [0.31]
 [0.65]
 [0.28]
 [-0.48]
 [0.92]
 [-0.39]
 [2.46]
 [2.91]
 [-0.73]
 [1.83]]
obs is : <class 'numpy.ndarray'>, its shape is : (27,), print for obs : [0.78 0.99 0.09 0.03 0.10 -0.03 -0.04 -0.09 -0.07 -0.01 0.03 -0.07 0.01
 -0.00 -0.09 0.07 0.08 -0.21 -0.05 -0.10 -0.06 0.02 0.00 -0.10 -0.06 0.04
 0.03]
AFTER RESHAPE
latent is : <class 'torch.Tensor'>, its shape is : torch.Size([68, 1]), print for latent : tensor([[ 0.4275],
        [ 2.6741],
        [-2.6953],
        [-2.5941],
        [-3.0146],
        [ 2.0899],
        [ 2.3249],
        [ 3.0072],
        [ 1.8797],
        [-0.2420],
        [ 0.8791],
        [ 2.7939],
        [-0.5362],
        [-1.4793],
        [-0.2755],
        [ 0.4300],
        [-3.0235],
        [ 0.7391],
        [ 0.7043],
        [ 0.7347],
        [ 2.7882],
        [-0.8827],
        [-0.3956],
        [-2.7632],
        [-1.1597],
        [-0.8563],
        [ 0.4411],
        [-0.3858],
        [ 3.0685],
        [-2.5004],
        [-1.5501],
        [-0.2117],
        [-0.8248],
        [ 2.0169],
        [-2.5315],
        [ 2.1234],
        [-2.5378],
        [ 2.9937],
        [-0.1970],
        [ 2.9956],
        [ 0.6588],
        [-2.8954],
        [-1.3647],
        [-1.2809],
        [-1.1436],
        [-0.5387],
        [-2.7385],
        [ 0.4185],
        [-1.4741],
        [-2.5513],
        [ 0.4772],
        [ 2.6973],
        [-1.1400],
        [-1.3232],
        [ 0.5436],
        [-3.0153],
        [ 2.0668],
        [-3.1121],
        [ 0.3067],
        [ 0.6457],
        [ 0.2820],
        [-0.4797],
        [ 0.9167],
        [-0.3922],
        [ 2.4616],
        [ 2.9133],
        [-0.7324],
        [ 1.8330]], device='cuda:0')
obs is : <class 'torch.Tensor'>, its shape is : torch.Size([68, 27]), print for obs : tensor([[ 0.7804,  0.9911,  0.0881,  ..., -0.0556,  0.0383,  0.0336],
        [ 0.7804,  0.9911,  0.0881,  ..., -0.0556,  0.0383,  0.0336],
        [ 0.7804,  0.9911,  0.0881,  ..., -0.0556,  0.0383,  0.0336],
        ...,
        [ 0.7804,  0.9911,  0.0881,  ..., -0.0556,  0.0383,  0.0336],
        [ 0.7804,  0.9911,  0.0881,  ..., -0.0556,  0.0383,  0.0336],
        [ 0.7804,  0.9911,  0.0881,  ..., -0.0556,  0.0383,  0.0336]],
       device='cuda:0')
Latents is : <class 'numpy.ndarray'>, its shape is : (6, 1), print for latent : [[1.76]
 [0.74]
 [0.70]
 [0.73]
 [3.07]
 [2.02]]
obs is : <class 'numpy.ndarray'>, its shape is : (27,), print for obs : [0.79 1.00 -0.01 0.06 0.03 0.02 0.01 -0.07 -0.09 0.01 0.05 0.10 -0.07
 -0.01 -0.07 0.03 0.09 -0.03 -0.06 -0.00 0.09 -0.05 0.05 0.04 0.03 -0.04
 0.08]
AFTER RESHAPE
latent is : <class 'torch.Tensor'>, its shape is : torch.Size([6, 1]), print for latent : tensor([[1.7626],
        [0.7391],
        [0.7043],
        [0.7347],
        [3.0685],
        [2.0169]], device='cuda:0')
obs is : <class 'torch.Tensor'>, its shape is : torch.Size([6, 27]), print for obs : tensor([[ 0.7928,  0.9980, -0.0077,  0.0550,  0.0303,  0.0240,  0.0107, -0.0731,
         -0.0867,  0.0083,  0.0459,  0.0964, -0.0701, -0.0068, -0.0702,  0.0297,
          0.0882, -0.0330, -0.0579, -0.0021,  0.0932, -0.0482,  0.0542,  0.0447,
          0.0334, -0.0439,  0.0817],
        [ 0.7928,  0.9980, -0.0077,  0.0550,  0.0303,  0.0240,  0.0107, -0.0731,
         -0.0867,  0.0083,  0.0459,  0.0964, -0.0701, -0.0068, -0.0702,  0.0297,
          0.0882, -0.0330, -0.0579, -0.0021,  0.0932, -0.0482,  0.0542,  0.0447,
          0.0334, -0.0439,  0.0817],
        [ 0.7928,  0.9980, -0.0077,  0.0550,  0.0303,  0.0240,  0.0107, -0.0731,
         -0.0867,  0.0083,  0.0459,  0.0964, -0.0701, -0.0068, -0.0702,  0.0297,
          0.0882, -0.0330, -0.0579, -0.0021,  0.0932, -0.0482,  0.0542,  0.0447,
          0.0334, -0.0439,  0.0817],
        [ 0.7928,  0.9980, -0.0077,  0.0550,  0.0303,  0.0240,  0.0107, -0.0731,
         -0.0867,  0.0083,  0.0459,  0.0964, -0.0701, -0.0068, -0.0702,  0.0297,
          0.0882, -0.0330, -0.0579, -0.0021,  0.0932, -0.0482,  0.0542,  0.0447,
          0.0334, -0.0439,  0.0817],
        [ 0.7928,  0.9980, -0.0077,  0.0550,  0.0303,  0.0240,  0.0107, -0.0731,
         -0.0867,  0.0083,  0.0459,  0.0964, -0.0701, -0.0068, -0.0702,  0.0297,
          0.0882, -0.0330, -0.0579, -0.0021,  0.0932, -0.0482,  0.0542,  0.0447,
          0.0334, -0.0439,  0.0817],
        [ 0.7928,  0.9980, -0.0077,  0.0550,  0.0303,  0.0240,  0.0107, -0.0731,
         -0.0867,  0.0083,  0.0459,  0.0964, -0.0701, -0.0068, -0.0702,  0.0297,
          0.0882, -0.0330, -0.0579, -0.0021,  0.0932, -0.0482,  0.0542,  0.0447,
          0.0334, -0.0439,  0.0817]], device='cuda:0')
Latents is : <class 'numpy.ndarray'>, its shape is : (100, 1), print for latent : [[0.43]
 [2.67]
 [-2.70]
 [-2.59]
 [-3.01]
 [2.09]
 [1.75]
 [2.32]
 [3.01]
 [1.88]
 [-0.24]
 [1.76]
 [-2.40]
 [0.88]
 [-2.24]
 [2.79]
 [0.14]
 [-0.54]
 [-1.48]
 [1.72]
 [-0.28]
 [0.43]
 [-3.02]
 [0.74]
 [0.70]
 [0.73]
 [2.79]
 [1.14]
 [-0.88]
 [-0.40]
 [1.24]
 [-2.76]
 [1.05]
 [1.07]
 [-1.82]
 [-2.33]
 [-1.16]
 [-0.86]
 [0.44]
 [-0.39]
 [3.07]
 [-2.50]
 [-1.83]
 [-2.13]
 [0.96]
 [-1.55]
 [-0.21]
 [-1.61]
 [-2.14]
 [-2.45]
 [0.98]
 [-2.27]
 [-1.91]
 [-0.82]
 [2.02]
 [-2.53]
 [2.12]
 [-2.54]
 [2.99]
 [-0.20]
 [3.00]
 [0.66]
 [1.50]
 [-2.90]
 [-1.36]
 [-2.39]
 [-1.28]
 [-2.40]
 [-1.14]
 [-0.54]
 [-2.74]
 [1.21]
 [0.42]
 [-1.47]
 [0.15]
 [-2.55]
 [0.48]
 [2.70]
 [-1.14]
 [1.05]
 [-2.31]
 [1.36]
 [-1.32]
 [-1.99]
 [0.54]
 [-3.02]
 [2.07]
 [-3.11]
 [0.31]
 [1.35]
 [0.65]
 [0.28]
 [-0.48]
 [0.92]
 [-0.39]
 [2.46]
 [2.91]
 [-0.73]
 [1.83]
 [0.18]]
obs is : <class 'numpy.ndarray'>, its shape is : (27,), print for obs : [0.78 1.00 0.03 -0.05 -0.00 -0.08 -0.08 0.05 -0.07 0.03 -0.04 0.05 -0.09
 0.03 -0.02 -0.09 -0.07 -0.15 0.04 0.07 -0.09 0.01 -0.06 0.11 -0.03 -0.09
 0.02]
AFTER RESHAPE
latent is : <class 'torch.Tensor'>, its shape is : torch.Size([100, 1]), print for latent : tensor([[ 0.4275],
        [ 2.6741],
        [-2.6953],
        [-2.5941],
        [-3.0146],
        [ 2.0899],
        [ 1.7477],
        [ 2.3249],
        [ 3.0072],
        [ 1.8797],
        [-0.2420],
        [ 1.7626],
        [-2.3985],
        [ 0.8791],
        [-2.2409],
        [ 2.7939],
        [ 0.1373],
        [-0.5362],
        [-1.4793],
        [ 1.7231],
        [-0.2755],
        [ 0.4300],
        [-3.0235],
        [ 0.7391],
        [ 0.7043],
        [ 0.7347],
        [ 2.7882],
        [ 1.1424],
        [-0.8827],
        [-0.3956],
        [ 1.2418],
        [-2.7632],
        [ 1.0478],
        [ 1.0721],
        [-1.8197],
        [-2.3315],
        [-1.1597],
        [-0.8563],
        [ 0.4411],
        [-0.3858],
        [ 3.0685],
        [-2.5004],
        [-1.8292],
        [-2.1281],
        [ 0.9620],
        [-1.5501],
        [-0.2117],
        [-1.6058],
        [-2.1428],
        [-2.4481],
        [ 0.9822],
        [-2.2734],
        [-1.9064],
        [-0.8248],
        [ 2.0169],
        [-2.5315],
        [ 2.1234],
        [-2.5378],
        [ 2.9937],
        [-0.1970],
        [ 2.9956],
        [ 0.6588],
        [ 1.5033],
        [-2.8954],
        [-1.3647],
        [-2.3864],
        [-1.2809],
        [-2.3956],
        [-1.1436],
        [-0.5387],
        [-2.7385],
        [ 1.2093],
        [ 0.4185],
        [-1.4741],
        [ 0.1461],
        [-2.5513],
        [ 0.4772],
        [ 2.6973],
        [-1.1400],
        [ 1.0519],
        [-2.3135],
        [ 1.3592],
        [-1.3232],
        [-1.9906],
        [ 0.5436],
        [-3.0153],
        [ 2.0668],
        [-3.1121],
        [ 0.3067],
        [ 1.3521],
        [ 0.6457],
        [ 0.2820],
        [-0.4797],
        [ 0.9167],
        [-0.3922],
        [ 2.4616],
        [ 2.9133],
        [-0.7324],
        [ 1.8330],
        [ 0.1816]], device='cuda:0')
obs is : <class 'torch.Tensor'>, its shape is : torch.Size([100, 27]), print for obs : tensor([[ 0.7833,  0.9982,  0.0291,  ..., -0.0345, -0.0854,  0.0217],
        [ 0.7833,  0.9982,  0.0291,  ..., -0.0345, -0.0854,  0.0217],
        [ 0.7833,  0.9982,  0.0291,  ..., -0.0345, -0.0854,  0.0217],
        ...,
        [ 0.7833,  0.9982,  0.0291,  ..., -0.0345, -0.0854,  0.0217],
        [ 0.7833,  0.9982,  0.0291,  ..., -0.0345, -0.0854,  0.0217],
        [ 0.7833,  0.9982,  0.0291,  ..., -0.0345, -0.0854,  0.0217]],
       device='cuda:0')
Self.relabel is : True
Latents is : <class 'numpy.ndarray'>, its shape is : (30, 1), print for latent : [[0.48]
 [0.58]
 [0.45]
 [-0.33]
 [1.25]
 [0.51]
 [1.21]
 [0.01]
 [0.67]
 [-3.02]
 [-0.45]
 [0.44]
 [0.57]
 [0.47]
 [-0.43]
 [-0.40]
 [3.13]
 [0.43]
 [1.24]
 [-0.29]
 [-3.07]
 [0.13]
 [-3.03]
 [-2.94]
 [0.49]
 [0.22]
 [0.56]
 [-0.06]
 [-0.41]
 [1.12]]
obs is : <class 'numpy.ndarray'>, its shape is : (27,), print for obs : [0.68 0.99 0.10 -0.09 0.09 0.07 -0.02 0.07 -0.03 -0.08 0.09 -0.09 0.06
 0.01 -0.05 -0.08 0.04 -0.00 0.02 0.03 -0.25 -0.06 0.08 0.07 -0.00 0.05
 0.13]
AFTER RESHAPE
latent is : <class 'torch.Tensor'>, its shape is : torch.Size([30, 1]), print for latent : tensor([[ 0.4785],
        [ 0.5783],
        [ 0.4540],
        [-0.3322],
        [ 1.2534],
        [ 0.5107],
        [ 1.2097],
        [ 0.0083],
        [ 0.6685],
        [-3.0210],
        [-0.4476],
        [ 0.4396],
        [ 0.5710],
        [ 0.4670],
        [-0.4309],
        [-0.4030],
        [ 3.1343],
        [ 0.4342],
        [ 1.2405],
        [-0.2919],
        [-3.0680],
        [ 0.1322],
        [-3.0252],
        [-2.9415],
        [ 0.4852],
        [ 0.2239],
        [ 0.5649],
        [-0.0599],
        [-0.4121],
        [ 1.1173]], device='cuda:0')
obs is : <class 'torch.Tensor'>, its shape is : torch.Size([30, 27]), print for obs : tensor([[ 0.6831,  0.9866,  0.1008, -0.0887,  0.0926,  0.0663, -0.0174,  0.0721,
         -0.0281, -0.0831,  0.0945, -0.0868,  0.0584,  0.0100, -0.0473, -0.0842,
          0.0374, -0.0014,  0.0199,  0.0280, -0.2532, -0.0614,  0.0754,  0.0737,
         -0.0019,  0.0505,  0.1251],
        [ 0.6831,  0.9866,  0.1008, -0.0887,  0.0926,  0.0663, -0.0174,  0.0721,
         -0.0281, -0.0831,  0.0945, -0.0868,  0.0584,  0.0100, -0.0473, -0.0842,
          0.0374, -0.0014,  0.0199,  0.0280, -0.2532, -0.0614,  0.0754,  0.0737,
         -0.0019,  0.0505,  0.1251],
        [ 0.6831,  0.9866,  0.1008, -0.0887,  0.0926,  0.0663, -0.0174,  0.0721,
         -0.0281, -0.0831,  0.0945, -0.0868,  0.0584,  0.0100, -0.0473, -0.0842,
          0.0374, -0.0014,  0.0199,  0.0280, -0.2532, -0.0614,  0.0754,  0.0737,
         -0.0019,  0.0505,  0.1251],
        [ 0.6831,  0.9866,  0.1008, -0.0887,  0.0926,  0.0663, -0.0174,  0.0721,
         -0.0281, -0.0831,  0.0945, -0.0868,  0.0584,  0.0100, -0.0473, -0.0842,
          0.0374, -0.0014,  0.0199,  0.0280, -0.2532, -0.0614,  0.0754,  0.0737,
         -0.0019,  0.0505,  0.1251],
        [ 0.6831,  0.9866,  0.1008, -0.0887,  0.0926,  0.0663, -0.0174,  0.0721,
         -0.0281, -0.0831,  0.0945, -0.0868,  0.0584,  0.0100, -0.0473, -0.0842,
          0.0374, -0.0014,  0.0199,  0.0280, -0.2532, -0.0614,  0.0754,  0.0737,
         -0.0019,  0.0505,  0.1251],
        [ 0.6831,  0.9866,  0.1008, -0.0887,  0.0926,  0.0663, -0.0174,  0.0721,
         -0.0281, -0.0831,  0.0945, -0.0868,  0.0584,  0.0100, -0.0473, -0.0842,
          0.0374, -0.0014,  0.0199,  0.0280, -0.2532, -0.0614,  0.0754,  0.0737,
         -0.0019,  0.0505,  0.1251],
        [ 0.6831,  0.9866,  0.1008, -0.0887,  0.0926,  0.0663, -0.0174,  0.0721,
         -0.0281, -0.0831,  0.0945, -0.0868,  0.0584,  0.0100, -0.0473, -0.0842,
          0.0374, -0.0014,  0.0199,  0.0280, -0.2532, -0.0614,  0.0754,  0.0737,
         -0.0019,  0.0505,  0.1251],
        [ 0.6831,  0.9866,  0.1008, -0.0887,  0.0926,  0.0663, -0.0174,  0.0721,
         -0.0281, -0.0831,  0.0945, -0.0868,  0.0584,  0.0100, -0.0473, -0.0842,
          0.0374, -0.0014,  0.0199,  0.0280, -0.2532, -0.0614,  0.0754,  0.0737,
         -0.0019,  0.0505,  0.1251],
        [ 0.6831,  0.9866,  0.1008, -0.0887,  0.0926,  0.0663, -0.0174,  0.0721,
         -0.0281, -0.0831,  0.0945, -0.0868,  0.0584,  0.0100, -0.0473, -0.0842,
          0.0374, -0.0014,  0.0199,  0.0280, -0.2532, -0.0614,  0.0754,  0.0737,
         -0.0019,  0.0505,  0.1251],
        [ 0.6831,  0.9866,  0.1008, -0.0887,  0.0926,  0.0663, -0.0174,  0.0721,
         -0.0281, -0.0831,  0.0945, -0.0868,  0.0584,  0.0100, -0.0473, -0.0842,
          0.0374, -0.0014,  0.0199,  0.0280, -0.2532, -0.0614,  0.0754,  0.0737,
         -0.0019,  0.0505,  0.1251],
        [ 0.6831,  0.9866,  0.1008, -0.0887,  0.0926,  0.0663, -0.0174,  0.0721,
         -0.0281, -0.0831,  0.0945, -0.0868,  0.0584,  0.0100, -0.0473, -0.0842,
          0.0374, -0.0014,  0.0199,  0.0280, -0.2532, -0.0614,  0.0754,  0.0737,
         -0.0019,  0.0505,  0.1251],
        [ 0.6831,  0.9866,  0.1008, -0.0887,  0.0926,  0.0663, -0.0174,  0.0721,
         -0.0281, -0.0831,  0.0945, -0.0868,  0.0584,  0.0100, -0.0473, -0.0842,
          0.0374, -0.0014,  0.0199,  0.0280, -0.2532, -0.0614,  0.0754,  0.0737,
         -0.0019,  0.0505,  0.1251],
        [ 0.6831,  0.9866,  0.1008, -0.0887,  0.0926,  0.0663, -0.0174,  0.0721,
         -0.0281, -0.0831,  0.0945, -0.0868,  0.0584,  0.0100, -0.0473, -0.0842,
          0.0374, -0.0014,  0.0199,  0.0280, -0.2532, -0.0614,  0.0754,  0.0737,
         -0.0019,  0.0505,  0.1251],
        [ 0.6831,  0.9866,  0.1008, -0.0887,  0.0926,  0.0663, -0.0174,  0.0721,
         -0.0281, -0.0831,  0.0945, -0.0868,  0.0584,  0.0100, -0.0473, -0.0842,
          0.0374, -0.0014,  0.0199,  0.0280, -0.2532, -0.0614,  0.0754,  0.0737,
         -0.0019,  0.0505,  0.1251],
        [ 0.6831,  0.9866,  0.1008, -0.0887,  0.0926,  0.0663, -0.0174,  0.0721,
         -0.0281, -0.0831,  0.0945, -0.0868,  0.0584,  0.0100, -0.0473, -0.0842,
          0.0374, -0.0014,  0.0199,  0.0280, -0.2532, -0.0614,  0.0754,  0.0737,
         -0.0019,  0.0505,  0.1251],
        [ 0.6831,  0.9866,  0.1008, -0.0887,  0.0926,  0.0663, -0.0174,  0.0721,
         -0.0281, -0.0831,  0.0945, -0.0868,  0.0584,  0.0100, -0.0473, -0.0842,
          0.0374, -0.0014,  0.0199,  0.0280, -0.2532, -0.0614,  0.0754,  0.0737,
         -0.0019,  0.0505,  0.1251],
        [ 0.6831,  0.9866,  0.1008, -0.0887,  0.0926,  0.0663, -0.0174,  0.0721,
         -0.0281, -0.0831,  0.0945, -0.0868,  0.0584,  0.0100, -0.0473, -0.0842,
          0.0374, -0.0014,  0.0199,  0.0280, -0.2532, -0.0614,  0.0754,  0.0737,
         -0.0019,  0.0505,  0.1251],
        [ 0.6831,  0.9866,  0.1008, -0.0887,  0.0926,  0.0663, -0.0174,  0.0721,
         -0.0281, -0.0831,  0.0945, -0.0868,  0.0584,  0.0100, -0.0473, -0.0842,
          0.0374, -0.0014,  0.0199,  0.0280, -0.2532, -0.0614,  0.0754,  0.0737,
         -0.0019,  0.0505,  0.1251],
        [ 0.6831,  0.9866,  0.1008, -0.0887,  0.0926,  0.0663, -0.0174,  0.0721,
         -0.0281, -0.0831,  0.0945, -0.0868,  0.0584,  0.0100, -0.0473, -0.0842,
          0.0374, -0.0014,  0.0199,  0.0280, -0.2532, -0.0614,  0.0754,  0.0737,
         -0.0019,  0.0505,  0.1251],
        [ 0.6831,  0.9866,  0.1008, -0.0887,  0.0926,  0.0663, -0.0174,  0.0721,
         -0.0281, -0.0831,  0.0945, -0.0868,  0.0584,  0.0100, -0.0473, -0.0842,
          0.0374, -0.0014,  0.0199,  0.0280, -0.2532, -0.0614,  0.0754,  0.0737,
         -0.0019,  0.0505,  0.1251],
        [ 0.6831,  0.9866,  0.1008, -0.0887,  0.0926,  0.0663, -0.0174,  0.0721,
         -0.0281, -0.0831,  0.0945, -0.0868,  0.0584,  0.0100, -0.0473, -0.0842,
          0.0374, -0.0014,  0.0199,  0.0280, -0.2532, -0.0614,  0.0754,  0.0737,
         -0.0019,  0.0505,  0.1251],
        [ 0.6831,  0.9866,  0.1008, -0.0887,  0.0926,  0.0663, -0.0174,  0.0721,
         -0.0281, -0.0831,  0.0945, -0.0868,  0.0584,  0.0100, -0.0473, -0.0842,
          0.0374, -0.0014,  0.0199,  0.0280, -0.2532, -0.0614,  0.0754,  0.0737,
         -0.0019,  0.0505,  0.1251],
        [ 0.6831,  0.9866,  0.1008, -0.0887,  0.0926,  0.0663, -0.0174,  0.0721,
         -0.0281, -0.0831,  0.0945, -0.0868,  0.0584,  0.0100, -0.0473, -0.0842,
          0.0374, -0.0014,  0.0199,  0.0280, -0.2532, -0.0614,  0.0754,  0.0737,
         -0.0019,  0.0505,  0.1251],
        [ 0.6831,  0.9866,  0.1008, -0.0887,  0.0926,  0.0663, -0.0174,  0.0721,
         -0.0281, -0.0831,  0.0945, -0.0868,  0.0584,  0.0100, -0.0473, -0.0842,
          0.0374, -0.0014,  0.0199,  0.0280, -0.2532, -0.0614,  0.0754,  0.0737,
         -0.0019,  0.0505,  0.1251],
        [ 0.6831,  0.9866,  0.1008, -0.0887,  0.0926,  0.0663, -0.0174,  0.0721,
         -0.0281, -0.0831,  0.0945, -0.0868,  0.0584,  0.0100, -0.0473, -0.0842,
          0.0374, -0.0014,  0.0199,  0.0280, -0.2532, -0.0614,  0.0754,  0.0737,
         -0.0019,  0.0505,  0.1251],
        [ 0.6831,  0.9866,  0.1008, -0.0887,  0.0926,  0.0663, -0.0174,  0.0721,
         -0.0281, -0.0831,  0.0945, -0.0868,  0.0584,  0.0100, -0.0473, -0.0842,
          0.0374, -0.0014,  0.0199,  0.0280, -0.2532, -0.0614,  0.0754,  0.0737,
         -0.0019,  0.0505,  0.1251],
        [ 0.6831,  0.9866,  0.1008, -0.0887,  0.0926,  0.0663, -0.0174,  0.0721,
         -0.0281, -0.0831,  0.0945, -0.0868,  0.0584,  0.0100, -0.0473, -0.0842,
          0.0374, -0.0014,  0.0199,  0.0280, -0.2532, -0.0614,  0.0754,  0.0737,
         -0.0019,  0.0505,  0.1251],
        [ 0.6831,  0.9866,  0.1008, -0.0887,  0.0926,  0.0663, -0.0174,  0.0721,
         -0.0281, -0.0831,  0.0945, -0.0868,  0.0584,  0.0100, -0.0473, -0.0842,
          0.0374, -0.0014,  0.0199,  0.0280, -0.2532, -0.0614,  0.0754,  0.0737,
         -0.0019,  0.0505,  0.1251],
        [ 0.6831,  0.9866,  0.1008, -0.0887,  0.0926,  0.0663, -0.0174,  0.0721,
         -0.0281, -0.0831,  0.0945, -0.0868,  0.0584,  0.0100, -0.0473, -0.0842,
          0.0374, -0.0014,  0.0199,  0.0280, -0.2532, -0.0614,  0.0754,  0.0737,
         -0.0019,  0.0505,  0.1251],
        [ 0.6831,  0.9866,  0.1008, -0.0887,  0.0926,  0.0663, -0.0174,  0.0721,
         -0.0281, -0.0831,  0.0945, -0.0868,  0.0584,  0.0100, -0.0473, -0.0842,
          0.0374, -0.0014,  0.0199,  0.0280, -0.2532, -0.0614,  0.0754,  0.0737,
         -0.0019,  0.0505,  0.1251]], device='cuda:0')
2022-04-10 11:57:10.404362 EDT | [gher-AntEnv-SAC-1000e-1000s-disc0.99-horizon1000_2022_04_10_11_56_30_0000--s-0] Epoch 0 finished
-------------------------------------------------  ---------------
replay_buffer/size                                  4000
trainer/QF1 Loss                                      24.3381
trainer/QF2 Loss                                      24.3182
trainer/Policy Loss                                   -5.33368
trainer/Q1 Predictions Mean                            0.00205658
trainer/Q1 Predictions Std                             0.00371642
trainer/Q1 Predictions Max                             0.012297
trainer/Q1 Predictions Min                            -0.0103556
trainer/Q2 Predictions Mean                            0.00408053
trainer/Q2 Predictions Std                             0.00301543
trainer/Q2 Predictions Max                             0.0143095
trainer/Q2 Predictions Min                            -0.0015658
trainer/Q Targets Mean                                 4.85385
trainer/Q Targets Std                                  0.893275
trainer/Q Targets Max                                  7.73077
trainer/Q Targets Min                                 -0.780566
trainer/Log Pis Mean                                  -5.33284
trainer/Log Pis Std                                    0.620023
trainer/Log Pis Max                                   -3.67747
trainer/Log Pis Min                                   -6.85216
trainer/Policy mu Mean                                -0.000273757
trainer/Policy mu Std                                  0.0020634
trainer/Policy mu Max                                  0.00579629
trainer/Policy mu Min                                 -0.00672824
trainer/Policy log std Mean                            2.44806e-05
trainer/Policy log std Std                             0.00224354
trainer/Policy log std Max                             0.00834457
trainer/Policy log std Min                            -0.00630654
trainer/Alpha                                          0.997005
trainer/Alpha Loss                                    -0
exploration/num steps total                         2000
exploration/num paths total                           13
exploration/path length Mean                        1000
exploration/path length Std                            0
exploration/path length Max                         1000
exploration/path length Min                         1000
exploration/Rewards Mean                              -0.542774
exploration/Rewards Std                                0.457468
exploration/Rewards Max                                0.757318
exploration/Rewards Min                               -1.87946
exploration/Returns Mean                            -542.774
exploration/Returns Std                                0
exploration/Returns Max                             -542.774
exploration/Returns Min                             -542.774
exploration/Actions Mean                              -0.0107755
exploration/Actions Std                                0.627318
exploration/Actions Max                                0.999344
exploration/Actions Min                               -0.998697
exploration/Num Paths                                  1
exploration/Average Returns                         -542.774
exploration/env_infos/final/reward_forward Mean       -0.937791
exploration/env_infos/final/reward_forward Std         0
exploration/env_infos/final/reward_forward Max        -0.937791
exploration/env_infos/final/reward_forward Min        -0.937791
exploration/env_infos/initial/reward_forward Mean     -0.245208
exploration/env_infos/initial/reward_forward Std       0
exploration/env_infos/initial/reward_forward Max      -0.245208
exploration/env_infos/initial/reward_forward Min      -0.245208
exploration/env_infos/reward_forward Mean             -0.0153051
exploration/env_infos/reward_forward Std               0.40941
exploration/env_infos/reward_forward Max               1.34802
exploration/env_infos/reward_forward Min              -1.30987
exploration/env_infos/final/reward_ctrl Mean          -0.53158
exploration/env_infos/final/reward_ctrl Std            0
exploration/env_infos/final/reward_ctrl Max           -0.53158
exploration/env_infos/final/reward_ctrl Min           -0.53158
exploration/env_infos/initial/reward_ctrl Mean        -2.5683
exploration/env_infos/initial/reward_ctrl Std          0
exploration/env_infos/initial/reward_ctrl Max         -2.5683
exploration/env_infos/initial/reward_ctrl Min         -2.5683
exploration/env_infos/reward_ctrl Mean                -1.57458
exploration/env_infos/reward_ctrl Std                  0.436626
exploration/env_infos/reward_ctrl Max                 -0.452347
exploration/env_infos/reward_ctrl Min                 -2.87946
exploration/env_infos/final/reward_contact Mean        0
exploration/env_infos/final/reward_contact Std         0
exploration/env_infos/final/reward_contact Max        -0
exploration/env_infos/final/reward_contact Min        -0
exploration/env_infos/initial/reward_contact Mean      0
exploration/env_infos/initial/reward_contact Std       0
exploration/env_infos/initial/reward_contact Max      -0
exploration/env_infos/initial/reward_contact Min      -0
exploration/env_infos/reward_contact Mean              0
exploration/env_infos/reward_contact Std               0
exploration/env_infos/reward_contact Max              -0
exploration/env_infos/reward_contact Min              -0
exploration/env_infos/final/reward_survive Mean        1
exploration/env_infos/final/reward_survive Std         0
exploration/env_infos/final/reward_survive Max         1
exploration/env_infos/final/reward_survive Min         1
exploration/env_infos/initial/reward_survive Mean      1
exploration/env_infos/initial/reward_survive Std       0
exploration/env_infos/initial/reward_survive Max       1
exploration/env_infos/initial/reward_survive Min       1
exploration/env_infos/reward_survive Mean              1
exploration/env_infos/reward_survive Std               0
exploration/env_infos/reward_survive Max               1
exploration/env_infos/reward_survive Min               1
exploration/env_infos/final/torso_velocity Mean       -0.753736
exploration/env_infos/final/torso_velocity Std         0.538224
exploration/env_infos/final/torso_velocity Max        -0.0220838
exploration/env_infos/final/torso_velocity Min        -1.30133
exploration/env_infos/initial/torso_velocity Mean     -0.0939087
exploration/env_infos/initial/torso_velocity Std       0.305757
exploration/env_infos/initial/torso_velocity Max       0.332543
exploration/env_infos/initial/torso_velocity Min      -0.369061
exploration/env_infos/torso_velocity Mean             -0.0124165
exploration/env_infos/torso_velocity Std               0.386853
exploration/env_infos/torso_velocity Max               2.12953
exploration/env_infos/torso_velocity Min              -1.97615
evaluation/num steps total                         25000
evaluation/num paths total                            25
evaluation/path length Mean                         1000
evaluation/path length Std                             0
evaluation/path length Max                          1000
evaluation/path length Min                          1000
evaluation/Rewards Mean                                1.00087
evaluation/Rewards Std                                 0.0137968
evaluation/Rewards Max                                 1.9387
evaluation/Rewards Min                                 0.999985
evaluation/Returns Mean                             1000.87
evaluation/Returns Std                                 1.19425
evaluation/Returns Max                              1004.96
evaluation/Returns Min                               999.995
evaluation/Actions Mean                               -0.000142339
evaluation/Actions Std                                 0.00116265
evaluation/Actions Max                                 0.00363763
evaluation/Actions Min                                -0.00391357
evaluation/Num Paths                                  25
evaluation/Average Returns                          1000.87
evaluation/env_infos/final/reward_forward Mean         0.000316401
evaluation/env_infos/final/reward_forward Std          0.00039551
evaluation/env_infos/final/reward_forward Max          0.00108226
evaluation/env_infos/final/reward_forward Min         -0.000812294
evaluation/env_infos/initial/reward_forward Mean       0.0188828
evaluation/env_infos/initial/reward_forward Std        0.107304
evaluation/env_infos/initial/reward_forward Max        0.251334
evaluation/env_infos/initial/reward_forward Min       -0.213328
evaluation/env_infos/reward_forward Mean               0.0011916
evaluation/env_infos/reward_forward Std                0.0425327
evaluation/env_infos/reward_forward Max                1.09935
evaluation/env_infos/reward_forward Min               -1.08093
evaluation/env_infos/final/reward_ctrl Mean           -5.44953e-06
evaluation/env_infos/final/reward_ctrl Std             6.56524e-07
evaluation/env_infos/final/reward_ctrl Max            -4.63024e-06
evaluation/env_infos/final/reward_ctrl Min            -6.85608e-06
evaluation/env_infos/initial/reward_ctrl Mean         -6.33315e-06
evaluation/env_infos/initial/reward_ctrl Std           4.85039e-07
evaluation/env_infos/initial/reward_ctrl Max          -5.24125e-06
evaluation/env_infos/initial/reward_ctrl Min          -7.06119e-06
evaluation/env_infos/reward_ctrl Mean                 -5.48805e-06
evaluation/env_infos/reward_ctrl Std                   7.75355e-07
evaluation/env_infos/reward_ctrl Max                  -3.35571e-06
evaluation/env_infos/reward_ctrl Min                  -1.47749e-05
evaluation/env_infos/final/reward_contact Mean         0
evaluation/env_infos/final/reward_contact Std          0
evaluation/env_infos/final/reward_contact Max         -0
evaluation/env_infos/final/reward_contact Min         -0
evaluation/env_infos/initial/reward_contact Mean       0
evaluation/env_infos/initial/reward_contact Std        0
evaluation/env_infos/initial/reward_contact Max       -0
evaluation/env_infos/initial/reward_contact Min       -0
evaluation/env_infos/reward_contact Mean               0
evaluation/env_infos/reward_contact Std                0
evaluation/env_infos/reward_contact Max               -0
evaluation/env_infos/reward_contact Min               -0
evaluation/env_infos/final/reward_survive Mean         1
evaluation/env_infos/final/reward_survive Std          0
evaluation/env_infos/final/reward_survive Max          1
evaluation/env_infos/final/reward_survive Min          1
evaluation/env_infos/initial/reward_survive Mean       1
evaluation/env_infos/initial/reward_survive Std        0
evaluation/env_infos/initial/reward_survive Max        1
evaluation/env_infos/initial/reward_survive Min        1
evaluation/env_infos/reward_survive Mean               1
evaluation/env_infos/reward_survive Std                0
evaluation/env_infos/reward_survive Max                1
evaluation/env_infos/reward_survive Min                1
evaluation/env_infos/final/torso_velocity Mean         0.000216405
evaluation/env_infos/final/torso_velocity Std          0.000442816
evaluation/env_infos/final/torso_velocity Max          0.00175655
evaluation/env_infos/final/torso_velocity Min         -0.000812294
evaluation/env_infos/initial/torso_velocity Mean       0.149462
evaluation/env_infos/initial/torso_velocity Std        0.22707
evaluation/env_infos/initial/torso_velocity Max        0.688954
evaluation/env_infos/initial/torso_velocity Min       -0.225782
evaluation/env_infos/torso_velocity Mean              -0.000956535
evaluation/env_infos/torso_velocity Std                0.051623
evaluation/env_infos/torso_velocity Max                1.09935
evaluation/env_infos/torso_velocity Min               -2.13683
time/data storing (s)                                  0.257222
time/evaluation sampling (s)                          27.8883
time/exploration sampling (s)                          1.21732
time/logging (s)                                       0.0923771
time/saving (s)                                        0.29413
time/training (s)                                      0.786216
time/epoch (s)                                        30.5356
time/total (s)                                        49.6623
Epoch                                                  0
-------------------------------------------------  ---------------
Self.relabel is : True
Latents is : <class 'numpy.ndarray'>, its shape is : (13, 1), print for latent : [[-0.16]
 [-0.29]
 [-0.34]
 [-1.07]
 [-0.41]
 [-1.22]
 [-0.38]
 [-1.13]
 [-0.31]
 [-0.19]
 [-0.28]
 [-1.08]
 [-1.22]]
obs is : <class 'numpy.ndarray'>, its shape is : (27,), print for obs : [0.68 0.99 0.02 0.07 0.09 -0.02 -0.09 0.08 0.06 0.08 0.06 -0.08 0.03 0.18
 -0.07 -0.03 -0.12 0.10 -0.06 0.19 -0.06 0.05 -0.01 0.01 0.21 -0.12 -0.02]
AFTER RESHAPE
latent is : <class 'torch.Tensor'>, its shape is : torch.Size([13, 1]), print for latent : tensor([[-0.1568],
        [-0.2946],
        [-0.3428],
        [-1.0688],
        [-0.4081],
        [-1.2200],
        [-0.3850],
        [-1.1335],
        [-0.3058],
        [-0.1906],
        [-0.2848],
        [-1.0799],
        [-1.2197]], device='cuda:0')
obs is : <class 'torch.Tensor'>, its shape is : torch.Size([13, 27]), print for obs : tensor([[ 0.6831,  0.9933,  0.0195,  0.0681,  0.0916, -0.0155, -0.0947,  0.0836,
          0.0642,  0.0821,  0.0556, -0.0813,  0.0250,  0.1794, -0.0722, -0.0323,
         -0.1171,  0.0992, -0.0576,  0.1920, -0.0574,  0.0499, -0.0065,  0.0067,
          0.2086, -0.1169, -0.0229],
        [ 0.6831,  0.9933,  0.0195,  0.0681,  0.0916, -0.0155, -0.0947,  0.0836,
          0.0642,  0.0821,  0.0556, -0.0813,  0.0250,  0.1794, -0.0722, -0.0323,
         -0.1171,  0.0992, -0.0576,  0.1920, -0.0574,  0.0499, -0.0065,  0.0067,
          0.2086, -0.1169, -0.0229],
        [ 0.6831,  0.9933,  0.0195,  0.0681,  0.0916, -0.0155, -0.0947,  0.0836,
          0.0642,  0.0821,  0.0556, -0.0813,  0.0250,  0.1794, -0.0722, -0.0323,
         -0.1171,  0.0992, -0.0576,  0.1920, -0.0574,  0.0499, -0.0065,  0.0067,
          0.2086, -0.1169, -0.0229],
        [ 0.6831,  0.9933,  0.0195,  0.0681,  0.0916, -0.0155, -0.0947,  0.0836,
          0.0642,  0.0821,  0.0556, -0.0813,  0.0250,  0.1794, -0.0722, -0.0323,
         -0.1171,  0.0992, -0.0576,  0.1920, -0.0574,  0.0499, -0.0065,  0.0067,
          0.2086, -0.1169, -0.0229],
        [ 0.6831,  0.9933,  0.0195,  0.0681,  0.0916, -0.0155, -0.0947,  0.0836,
          0.0642,  0.0821,  0.0556, -0.0813,  0.0250,  0.1794, -0.0722, -0.0323,
         -0.1171,  0.0992, -0.0576,  0.1920, -0.0574,  0.0499, -0.0065,  0.0067,
          0.2086, -0.1169, -0.0229],
        [ 0.6831,  0.9933,  0.0195,  0.0681,  0.0916, -0.0155, -0.0947,  0.0836,
          0.0642,  0.0821,  0.0556, -0.0813,  0.0250,  0.1794, -0.0722, -0.0323,
         -0.1171,  0.0992, -0.0576,  0.1920, -0.0574,  0.0499, -0.0065,  0.0067,
          0.2086, -0.1169, -0.0229],
        [ 0.6831,  0.9933,  0.0195,  0.0681,  0.0916, -0.0155, -0.0947,  0.0836,
          0.0642,  0.0821,  0.0556, -0.0813,  0.0250,  0.1794, -0.0722, -0.0323,
         -0.1171,  0.0992, -0.0576,  0.1920, -0.0574,  0.0499, -0.0065,  0.0067,
          0.2086, -0.1169, -0.0229],
        [ 0.6831,  0.9933,  0.0195,  0.0681,  0.0916, -0.0155, -0.0947,  0.0836,
          0.0642,  0.0821,  0.0556, -0.0813,  0.0250,  0.1794, -0.0722, -0.0323,
         -0.1171,  0.0992, -0.0576,  0.1920, -0.0574,  0.0499, -0.0065,  0.0067,
          0.2086, -0.1169, -0.0229],
        [ 0.6831,  0.9933,  0.0195,  0.0681,  0.0916, -0.0155, -0.0947,  0.0836,
          0.0642,  0.0821,  0.0556, -0.0813,  0.0250,  0.1794, -0.0722, -0.0323,
         -0.1171,  0.0992, -0.0576,  0.1920, -0.0574,  0.0499, -0.0065,  0.0067,
          0.2086, -0.1169, -0.0229],
        [ 0.6831,  0.9933,  0.0195,  0.0681,  0.0916, -0.0155, -0.0947,  0.0836,
          0.0642,  0.0821,  0.0556, -0.0813,  0.0250,  0.1794, -0.0722, -0.0323,
         -0.1171,  0.0992, -0.0576,  0.1920, -0.0574,  0.0499, -0.0065,  0.0067,
          0.2086, -0.1169, -0.0229],
        [ 0.6831,  0.9933,  0.0195,  0.0681,  0.0916, -0.0155, -0.0947,  0.0836,
          0.0642,  0.0821,  0.0556, -0.0813,  0.0250,  0.1794, -0.0722, -0.0323,
         -0.1171,  0.0992, -0.0576,  0.1920, -0.0574,  0.0499, -0.0065,  0.0067,
          0.2086, -0.1169, -0.0229],
        [ 0.6831,  0.9933,  0.0195,  0.0681,  0.0916, -0.0155, -0.0947,  0.0836,
          0.0642,  0.0821,  0.0556, -0.0813,  0.0250,  0.1794, -0.0722, -0.0323,
         -0.1171,  0.0992, -0.0576,  0.1920, -0.0574,  0.0499, -0.0065,  0.0067,
          0.2086, -0.1169, -0.0229],
        [ 0.6831,  0.9933,  0.0195,  0.0681,  0.0916, -0.0155, -0.0947,  0.0836,
          0.0642,  0.0821,  0.0556, -0.0813,  0.0250,  0.1794, -0.0722, -0.0323,
         -0.1171,  0.0992, -0.0576,  0.1920, -0.0574,  0.0499, -0.0065,  0.0067,
          0.2086, -0.1169, -0.0229]], device='cuda:0')
Latents is : <class 'numpy.ndarray'>, its shape is : (12, 1), print for latent : [[-1.97]
 [-1.67]
 [-1.88]
 [-1.82]
 [-2.38]
 [-1.94]
 [-1.66]
 [-2.17]
 [-1.75]
 [-1.71]
 [-2.33]
 [-2.27]]
obs is : <class 'numpy.ndarray'>, its shape is : (27,), print for obs : [0.72 0.99 -0.08 0.04 -0.06 -0.04 0.05 0.07 0.07 -0.04 -0.07 0.09 -0.08
 -0.12 0.03 0.05 -0.17 0.06 0.02 0.09 0.04 -0.12 0.03 -0.03 -0.07 -0.09
 -0.01]
AFTER RESHAPE
latent is : <class 'torch.Tensor'>, its shape is : torch.Size([12, 1]), print for latent : tensor([[-1.9696],
        [-1.6688],
        [-1.8782],
        [-1.8245],
        [-2.3776],
        [-1.9411],
        [-1.6593],
        [-2.1686],
        [-1.7514],
        [-1.7078],
        [-2.3324],
        [-2.2707]], device='cuda:0')
obs is : <class 'torch.Tensor'>, its shape is : torch.Size([12, 27]), print for obs : tensor([[ 0.7244,  0.9943, -0.0770,  0.0433, -0.0590, -0.0362,  0.0521,  0.0726,
          0.0691, -0.0438, -0.0708,  0.0884, -0.0807, -0.1199,  0.0335,  0.0469,
         -0.1673,  0.0608,  0.0170,  0.0934,  0.0431, -0.1170,  0.0348, -0.0265,
         -0.0687, -0.0875, -0.0065],
        [ 0.7244,  0.9943, -0.0770,  0.0433, -0.0590, -0.0362,  0.0521,  0.0726,
          0.0691, -0.0438, -0.0708,  0.0884, -0.0807, -0.1199,  0.0335,  0.0469,
         -0.1673,  0.0608,  0.0170,  0.0934,  0.0431, -0.1170,  0.0348, -0.0265,
         -0.0687, -0.0875, -0.0065],
        [ 0.7244,  0.9943, -0.0770,  0.0433, -0.0590, -0.0362,  0.0521,  0.0726,
          0.0691, -0.0438, -0.0708,  0.0884, -0.0807, -0.1199,  0.0335,  0.0469,
         -0.1673,  0.0608,  0.0170,  0.0934,  0.0431, -0.1170,  0.0348, -0.0265,
         -0.0687, -0.0875, -0.0065],
        [ 0.7244,  0.9943, -0.0770,  0.0433, -0.0590, -0.0362,  0.0521,  0.0726,
          0.0691, -0.0438, -0.0708,  0.0884, -0.0807, -0.1199,  0.0335,  0.0469,
         -0.1673,  0.0608,  0.0170,  0.0934,  0.0431, -0.1170,  0.0348, -0.0265,
         -0.0687, -0.0875, -0.0065],
        [ 0.7244,  0.9943, -0.0770,  0.0433, -0.0590, -0.0362,  0.0521,  0.0726,
          0.0691, -0.0438, -0.0708,  0.0884, -0.0807, -0.1199,  0.0335,  0.0469,
         -0.1673,  0.0608,  0.0170,  0.0934,  0.0431, -0.1170,  0.0348, -0.0265,
         -0.0687, -0.0875, -0.0065],
        [ 0.7244,  0.9943, -0.0770,  0.0433, -0.0590, -0.0362,  0.0521,  0.0726,
          0.0691, -0.0438, -0.0708,  0.0884, -0.0807, -0.1199,  0.0335,  0.0469,
         -0.1673,  0.0608,  0.0170,  0.0934,  0.0431, -0.1170,  0.0348, -0.0265,
         -0.0687, -0.0875, -0.0065],
        [ 0.7244,  0.9943, -0.0770,  0.0433, -0.0590, -0.0362,  0.0521,  0.0726,
          0.0691, -0.0438, -0.0708,  0.0884, -0.0807, -0.1199,  0.0335,  0.0469,
         -0.1673,  0.0608,  0.0170,  0.0934,  0.0431, -0.1170,  0.0348, -0.0265,
         -0.0687, -0.0875, -0.0065],
        [ 0.7244,  0.9943, -0.0770,  0.0433, -0.0590, -0.0362,  0.0521,  0.0726,
          0.0691, -0.0438, -0.0708,  0.0884, -0.0807, -0.1199,  0.0335,  0.0469,
         -0.1673,  0.0608,  0.0170,  0.0934,  0.0431, -0.1170,  0.0348, -0.0265,
         -0.0687, -0.0875, -0.0065],
        [ 0.7244,  0.9943, -0.0770,  0.0433, -0.0590, -0.0362,  0.0521,  0.0726,
          0.0691, -0.0438, -0.0708,  0.0884, -0.0807, -0.1199,  0.0335,  0.0469,
         -0.1673,  0.0608,  0.0170,  0.0934,  0.0431, -0.1170,  0.0348, -0.0265,
         -0.0687, -0.0875, -0.0065],
        [ 0.7244,  0.9943, -0.0770,  0.0433, -0.0590, -0.0362,  0.0521,  0.0726,
          0.0691, -0.0438, -0.0708,  0.0884, -0.0807, -0.1199,  0.0335,  0.0469,
         -0.1673,  0.0608,  0.0170,  0.0934,  0.0431, -0.1170,  0.0348, -0.0265,
         -0.0687, -0.0875, -0.0065],
        [ 0.7244,  0.9943, -0.0770,  0.0433, -0.0590, -0.0362,  0.0521,  0.0726,
          0.0691, -0.0438, -0.0708,  0.0884, -0.0807, -0.1199,  0.0335,  0.0469,
         -0.1673,  0.0608,  0.0170,  0.0934,  0.0431, -0.1170,  0.0348, -0.0265,
         -0.0687, -0.0875, -0.0065],
        [ 0.7244,  0.9943, -0.0770,  0.0433, -0.0590, -0.0362,  0.0521,  0.0726,
          0.0691, -0.0438, -0.0708,  0.0884, -0.0807, -0.1199,  0.0335,  0.0469,
         -0.1673,  0.0608,  0.0170,  0.0934,  0.0431, -0.1170,  0.0348, -0.0265,
         -0.0687, -0.0875, -0.0065]], device='cuda:0')
Latents is : <class 'numpy.ndarray'>, its shape is : (5, 1), print for latent : [[2.75]
 [2.77]
 [2.48]
 [2.58]
 [2.57]]
obs is : <class 'numpy.ndarray'>, its shape is : (27,), print for obs : [0.70 1.00 0.07 -0.01 0.06 -0.05 0.04 0.03 -0.07 0.09 -0.09 0.07 -0.01
 -0.12 0.10 -0.06 -0.13 0.20 -0.06 -0.12 0.12 -0.03 -0.14 -0.02 0.10 -0.13
 -0.12]
AFTER RESHAPE
latent is : <class 'torch.Tensor'>, its shape is : torch.Size([5, 1]), print for latent : tensor([[2.7500],
        [2.7743],
        [2.4791],
        [2.5812],
        [2.5715]], device='cuda:0')
obs is : <class 'torch.Tensor'>, its shape is : torch.Size([5, 27]), print for obs : tensor([[ 0.6969,  0.9956,  0.0735, -0.0110,  0.0579, -0.0540,  0.0434,  0.0255,
         -0.0735,  0.0885, -0.0916,  0.0662, -0.0091, -0.1223,  0.1027, -0.0600,
         -0.1338,  0.1988, -0.0640, -0.1153,  0.1223, -0.0267, -0.1365, -0.0243,
          0.1002, -0.1260, -0.1221],
        [ 0.6969,  0.9956,  0.0735, -0.0110,  0.0579, -0.0540,  0.0434,  0.0255,
         -0.0735,  0.0885, -0.0916,  0.0662, -0.0091, -0.1223,  0.1027, -0.0600,
         -0.1338,  0.1988, -0.0640, -0.1153,  0.1223, -0.0267, -0.1365, -0.0243,
          0.1002, -0.1260, -0.1221],
        [ 0.6969,  0.9956,  0.0735, -0.0110,  0.0579, -0.0540,  0.0434,  0.0255,
         -0.0735,  0.0885, -0.0916,  0.0662, -0.0091, -0.1223,  0.1027, -0.0600,
         -0.1338,  0.1988, -0.0640, -0.1153,  0.1223, -0.0267, -0.1365, -0.0243,
          0.1002, -0.1260, -0.1221],
        [ 0.6969,  0.9956,  0.0735, -0.0110,  0.0579, -0.0540,  0.0434,  0.0255,
         -0.0735,  0.0885, -0.0916,  0.0662, -0.0091, -0.1223,  0.1027, -0.0600,
         -0.1338,  0.1988, -0.0640, -0.1153,  0.1223, -0.0267, -0.1365, -0.0243,
          0.1002, -0.1260, -0.1221],
        [ 0.6969,  0.9956,  0.0735, -0.0110,  0.0579, -0.0540,  0.0434,  0.0255,
         -0.0735,  0.0885, -0.0916,  0.0662, -0.0091, -0.1223,  0.1027, -0.0600,
         -0.1338,  0.1988, -0.0640, -0.1153,  0.1223, -0.0267, -0.1365, -0.0243,
          0.1002, -0.1260, -0.1221]], device='cuda:0')
Latents is : <class 'numpy.ndarray'>, its shape is : (14, 1), print for latent : [[1.62]
 [0.51]
 [1.57]
 [0.35]
 [0.07]
 [0.21]
 [-0.11]
 [0.11]
 [0.57]
 [0.62]
 [0.24]
 [0.26]
 [0.60]
 [-0.11]]
obs is : <class 'numpy.ndarray'>, its shape is : (27,), print for obs : [0.81 0.99 0.00 0.07 0.07 0.06 0.07 -0.07 0.07 -0.09 -0.03 0.04 -0.03
 -0.13 -0.03 0.06 0.12 0.07 -0.14 0.10 0.05 0.13 -0.06 -0.10 0.07 -0.11
 -0.05]
AFTER RESHAPE
latent is : <class 'torch.Tensor'>, its shape is : torch.Size([14, 1]), print for latent : tensor([[ 1.6249],
        [ 0.5112],
        [ 1.5660],
        [ 0.3527],
        [ 0.0660],
        [ 0.2078],
        [-0.1120],
        [ 0.1054],
        [ 0.5730],
        [ 0.6214],
        [ 0.2379],
        [ 0.2589],
        [ 0.5978],
        [-0.1102]], device='cuda:0')
obs is : <class 'torch.Tensor'>, its shape is : torch.Size([14, 27]), print for obs : tensor([[ 0.8138,  0.9947,  0.0046,  0.0736,  0.0714,  0.0647,  0.0710, -0.0710,
          0.0692, -0.0852, -0.0291,  0.0439, -0.0341, -0.1258, -0.0329,  0.0627,
          0.1219,  0.0673, -0.1392,  0.0985,  0.0468,  0.1324, -0.0626, -0.1027,
          0.0690, -0.1110, -0.0511],
        [ 0.8138,  0.9947,  0.0046,  0.0736,  0.0714,  0.0647,  0.0710, -0.0710,
          0.0692, -0.0852, -0.0291,  0.0439, -0.0341, -0.1258, -0.0329,  0.0627,
          0.1219,  0.0673, -0.1392,  0.0985,  0.0468,  0.1324, -0.0626, -0.1027,
          0.0690, -0.1110, -0.0511],
        [ 0.8138,  0.9947,  0.0046,  0.0736,  0.0714,  0.0647,  0.0710, -0.0710,
          0.0692, -0.0852, -0.0291,  0.0439, -0.0341, -0.1258, -0.0329,  0.0627,
          0.1219,  0.0673, -0.1392,  0.0985,  0.0468,  0.1324, -0.0626, -0.1027,
          0.0690, -0.1110, -0.0511],
        [ 0.8138,  0.9947,  0.0046,  0.0736,  0.0714,  0.0647,  0.0710, -0.0710,
          0.0692, -0.0852, -0.0291,  0.0439, -0.0341, -0.1258, -0.0329,  0.0627,
          0.1219,  0.0673, -0.1392,  0.0985,  0.0468,  0.1324, -0.0626, -0.1027,
          0.0690, -0.1110, -0.0511],
        [ 0.8138,  0.9947,  0.0046,  0.0736,  0.0714,  0.0647,  0.0710, -0.0710,
          0.0692, -0.0852, -0.0291,  0.0439, -0.0341, -0.1258, -0.0329,  0.0627,
          0.1219,  0.0673, -0.1392,  0.0985,  0.0468,  0.1324, -0.0626, -0.1027,
          0.0690, -0.1110, -0.0511],
        [ 0.8138,  0.9947,  0.0046,  0.0736,  0.0714,  0.0647,  0.0710, -0.0710,
          0.0692, -0.0852, -0.0291,  0.0439, -0.0341, -0.1258, -0.0329,  0.0627,
          0.1219,  0.0673, -0.1392,  0.0985,  0.0468,  0.1324, -0.0626, -0.1027,
          0.0690, -0.1110, -0.0511],
        [ 0.8138,  0.9947,  0.0046,  0.0736,  0.0714,  0.0647,  0.0710, -0.0710,
          0.0692, -0.0852, -0.0291,  0.0439, -0.0341, -0.1258, -0.0329,  0.0627,
          0.1219,  0.0673, -0.1392,  0.0985,  0.0468,  0.1324, -0.0626, -0.1027,
          0.0690, -0.1110, -0.0511],
        [ 0.8138,  0.9947,  0.0046,  0.0736,  0.0714,  0.0647,  0.0710, -0.0710,
          0.0692, -0.0852, -0.0291,  0.0439, -0.0341, -0.1258, -0.0329,  0.0627,
          0.1219,  0.0673, -0.1392,  0.0985,  0.0468,  0.1324, -0.0626, -0.1027,
          0.0690, -0.1110, -0.0511],
        [ 0.8138,  0.9947,  0.0046,  0.0736,  0.0714,  0.0647,  0.0710, -0.0710,
          0.0692, -0.0852, -0.0291,  0.0439, -0.0341, -0.1258, -0.0329,  0.0627,
          0.1219,  0.0673, -0.1392,  0.0985,  0.0468,  0.1324, -0.0626, -0.1027,
          0.0690, -0.1110, -0.0511],
        [ 0.8138,  0.9947,  0.0046,  0.0736,  0.0714,  0.0647,  0.0710, -0.0710,
          0.0692, -0.0852, -0.0291,  0.0439, -0.0341, -0.1258, -0.0329,  0.0627,
          0.1219,  0.0673, -0.1392,  0.0985,  0.0468,  0.1324, -0.0626, -0.1027,
          0.0690, -0.1110, -0.0511],
        [ 0.8138,  0.9947,  0.0046,  0.0736,  0.0714,  0.0647,  0.0710, -0.0710,
          0.0692, -0.0852, -0.0291,  0.0439, -0.0341, -0.1258, -0.0329,  0.0627,
          0.1219,  0.0673, -0.1392,  0.0985,  0.0468,  0.1324, -0.0626, -0.1027,
          0.0690, -0.1110, -0.0511],
        [ 0.8138,  0.9947,  0.0046,  0.0736,  0.0714,  0.0647,  0.0710, -0.0710,
          0.0692, -0.0852, -0.0291,  0.0439, -0.0341, -0.1258, -0.0329,  0.0627,
          0.1219,  0.0673, -0.1392,  0.0985,  0.0468,  0.1324, -0.0626, -0.1027,
          0.0690, -0.1110, -0.0511],
        [ 0.8138,  0.9947,  0.0046,  0.0736,  0.0714,  0.0647,  0.0710, -0.0710,
          0.0692, -0.0852, -0.0291,  0.0439, -0.0341, -0.1258, -0.0329,  0.0627,
          0.1219,  0.0673, -0.1392,  0.0985,  0.0468,  0.1324, -0.0626, -0.1027,
          0.0690, -0.1110, -0.0511],
        [ 0.8138,  0.9947,  0.0046,  0.0736,  0.0714,  0.0647,  0.0710, -0.0710,
          0.0692, -0.0852, -0.0291,  0.0439, -0.0341, -0.1258, -0.0329,  0.0627,
          0.1219,  0.0673, -0.1392,  0.0985,  0.0468,  0.1324, -0.0626, -0.1027,
          0.0690, -0.1110, -0.0511]], device='cuda:0')
Latents is : <class 'numpy.ndarray'>, its shape is : (14, 1), print for latent : [[1.52]
 [1.82]
 [1.21]
 [1.25]
 [1.00]
 [1.47]
 [1.96]
 [1.78]
 [1.79]
 [1.36]
 [1.26]
 [1.35]
 [1.85]
 [1.16]]
obs is : <class 'numpy.ndarray'>, its shape is : (27,), print for obs : [0.65 1.00 -0.01 -0.07 -0.07 0.02 0.05 0.02 -0.07 0.09 0.09 -0.01 0.06
 -0.12 -0.05 -0.05 0.12 -0.02 0.10 -0.01 -0.03 0.07 -0.07 -0.11 0.01 -0.00
 -0.11]
AFTER RESHAPE
latent is : <class 'torch.Tensor'>, its shape is : torch.Size([14, 1]), print for latent : tensor([[1.5178],
        [1.8171],
        [1.2094],
        [1.2534],
        [0.9968],
        [1.4666],
        [1.9617],
        [1.7841],
        [1.7904],
        [1.3637],
        [1.2620],
        [1.3550],
        [1.8509],
        [1.1592]], device='cuda:0')
obs is : <class 'torch.Tensor'>, its shape is : torch.Size([14, 27]), print for obs : tensor([[ 0.6536,  0.9952, -0.0072, -0.0685, -0.0700,  0.0158,  0.0473,  0.0222,
         -0.0724,  0.0890,  0.0923, -0.0096,  0.0563, -0.1186, -0.0531, -0.0481,
          0.1157, -0.0172,  0.1018, -0.0134, -0.0300,  0.0746, -0.0726, -0.1055,
          0.0077, -0.0031, -0.1079],
        [ 0.6536,  0.9952, -0.0072, -0.0685, -0.0700,  0.0158,  0.0473,  0.0222,
         -0.0724,  0.0890,  0.0923, -0.0096,  0.0563, -0.1186, -0.0531, -0.0481,
          0.1157, -0.0172,  0.1018, -0.0134, -0.0300,  0.0746, -0.0726, -0.1055,
          0.0077, -0.0031, -0.1079],
        [ 0.6536,  0.9952, -0.0072, -0.0685, -0.0700,  0.0158,  0.0473,  0.0222,
         -0.0724,  0.0890,  0.0923, -0.0096,  0.0563, -0.1186, -0.0531, -0.0481,
          0.1157, -0.0172,  0.1018, -0.0134, -0.0300,  0.0746, -0.0726, -0.1055,
          0.0077, -0.0031, -0.1079],
        [ 0.6536,  0.9952, -0.0072, -0.0685, -0.0700,  0.0158,  0.0473,  0.0222,
         -0.0724,  0.0890,  0.0923, -0.0096,  0.0563, -0.1186, -0.0531, -0.0481,
          0.1157, -0.0172,  0.1018, -0.0134, -0.0300,  0.0746, -0.0726, -0.1055,
          0.0077, -0.0031, -0.1079],
        [ 0.6536,  0.9952, -0.0072, -0.0685, -0.0700,  0.0158,  0.0473,  0.0222,
         -0.0724,  0.0890,  0.0923, -0.0096,  0.0563, -0.1186, -0.0531, -0.0481,
          0.1157, -0.0172,  0.1018, -0.0134, -0.0300,  0.0746, -0.0726, -0.1055,
          0.0077, -0.0031, -0.1079],
        [ 0.6536,  0.9952, -0.0072, -0.0685, -0.0700,  0.0158,  0.0473,  0.0222,
         -0.0724,  0.0890,  0.0923, -0.0096,  0.0563, -0.1186, -0.0531, -0.0481,
          0.1157, -0.0172,  0.1018, -0.0134, -0.0300,  0.0746, -0.0726, -0.1055,
          0.0077, -0.0031, -0.1079],
        [ 0.6536,  0.9952, -0.0072, -0.0685, -0.0700,  0.0158,  0.0473,  0.0222,
         -0.0724,  0.0890,  0.0923, -0.0096,  0.0563, -0.1186, -0.0531, -0.0481,
          0.1157, -0.0172,  0.1018, -0.0134, -0.0300,  0.0746, -0.0726, -0.1055,
          0.0077, -0.0031, -0.1079],
        [ 0.6536,  0.9952, -0.0072, -0.0685, -0.0700,  0.0158,  0.0473,  0.0222,
         -0.0724,  0.0890,  0.0923, -0.0096,  0.0563, -0.1186, -0.0531, -0.0481,
          0.1157, -0.0172,  0.1018, -0.0134, -0.0300,  0.0746, -0.0726, -0.1055,
          0.0077, -0.0031, -0.1079],
        [ 0.6536,  0.9952, -0.0072, -0.0685, -0.0700,  0.0158,  0.0473,  0.0222,
         -0.0724,  0.0890,  0.0923, -0.0096,  0.0563, -0.1186, -0.0531, -0.0481,
          0.1157, -0.0172,  0.1018, -0.0134, -0.0300,  0.0746, -0.0726, -0.1055,
          0.0077, -0.0031, -0.1079],
        [ 0.6536,  0.9952, -0.0072, -0.0685, -0.0700,  0.0158,  0.0473,  0.0222,
         -0.0724,  0.0890,  0.0923, -0.0096,  0.0563, -0.1186, -0.0531, -0.0481,
          0.1157, -0.0172,  0.1018, -0.0134, -0.0300,  0.0746, -0.0726, -0.1055,
          0.0077, -0.0031, -0.1079],
        [ 0.6536,  0.9952, -0.0072, -0.0685, -0.0700,  0.0158,  0.0473,  0.0222,
         -0.0724,  0.0890,  0.0923, -0.0096,  0.0563, -0.1186, -0.0531, -0.0481,
          0.1157, -0.0172,  0.1018, -0.0134, -0.0300,  0.0746, -0.0726, -0.1055,
          0.0077, -0.0031, -0.1079],
        [ 0.6536,  0.9952, -0.0072, -0.0685, -0.0700,  0.0158,  0.0473,  0.0222,
         -0.0724,  0.0890,  0.0923, -0.0096,  0.0563, -0.1186, -0.0531, -0.0481,
          0.1157, -0.0172,  0.1018, -0.0134, -0.0300,  0.0746, -0.0726, -0.1055,
          0.0077, -0.0031, -0.1079],
        [ 0.6536,  0.9952, -0.0072, -0.0685, -0.0700,  0.0158,  0.0473,  0.0222,
         -0.0724,  0.0890,  0.0923, -0.0096,  0.0563, -0.1186, -0.0531, -0.0481,
          0.1157, -0.0172,  0.1018, -0.0134, -0.0300,  0.0746, -0.0726, -0.1055,
          0.0077, -0.0031, -0.1079],
        [ 0.6536,  0.9952, -0.0072, -0.0685, -0.0700,  0.0158,  0.0473,  0.0222,
         -0.0724,  0.0890,  0.0923, -0.0096,  0.0563, -0.1186, -0.0531, -0.0481,
          0.1157, -0.0172,  0.1018, -0.0134, -0.0300,  0.0746, -0.0726, -0.1055,
          0.0077, -0.0031, -0.1079]], device='cuda:0')
Latents is : <class 'numpy.ndarray'>, its shape is : (5, 1), print for latent : [[-0.87]
 [-0.80]
 [-0.90]
 [-0.80]
 [-0.79]]
obs is : <class 'numpy.ndarray'>, its shape is : (27,), print for obs : [0.67 1.00 0.01 -0.02 -0.06 0.09 0.05 -0.06 0.05 0.05 -0.05 0.05 0.04
 -0.08 0.04 0.12 0.00 0.05 -0.12 -0.11 -0.04 0.15 -0.06 -0.01 -0.02 0.11
 -0.15]
AFTER RESHAPE
latent is : <class 'torch.Tensor'>, its shape is : torch.Size([5, 1]), print for latent : tensor([[-0.8738],
        [-0.7973],
        [-0.8991],
        [-0.8042],
        [-0.7905]], device='cuda:0')
obs is : <class 'torch.Tensor'>, its shape is : torch.Size([5, 27]), print for obs : tensor([[ 0.6680,  0.9981,  0.0092, -0.0153, -0.0595,  0.0918,  0.0452, -0.0577,
          0.0471,  0.0502, -0.0496,  0.0482,  0.0363, -0.0798,  0.0357,  0.1164,
          0.0024,  0.0455, -0.1191, -0.1112, -0.0447,  0.1536, -0.0587, -0.0068,
         -0.0213,  0.1083, -0.1525],
        [ 0.6680,  0.9981,  0.0092, -0.0153, -0.0595,  0.0918,  0.0452, -0.0577,
          0.0471,  0.0502, -0.0496,  0.0482,  0.0363, -0.0798,  0.0357,  0.1164,
          0.0024,  0.0455, -0.1191, -0.1112, -0.0447,  0.1536, -0.0587, -0.0068,
         -0.0213,  0.1083, -0.1525],
        [ 0.6680,  0.9981,  0.0092, -0.0153, -0.0595,  0.0918,  0.0452, -0.0577,
          0.0471,  0.0502, -0.0496,  0.0482,  0.0363, -0.0798,  0.0357,  0.1164,
          0.0024,  0.0455, -0.1191, -0.1112, -0.0447,  0.1536, -0.0587, -0.0068,
         -0.0213,  0.1083, -0.1525],
        [ 0.6680,  0.9981,  0.0092, -0.0153, -0.0595,  0.0918,  0.0452, -0.0577,
          0.0471,  0.0502, -0.0496,  0.0482,  0.0363, -0.0798,  0.0357,  0.1164,
          0.0024,  0.0455, -0.1191, -0.1112, -0.0447,  0.1536, -0.0587, -0.0068,
         -0.0213,  0.1083, -0.1525],
        [ 0.6680,  0.9981,  0.0092, -0.0153, -0.0595,  0.0918,  0.0452, -0.0577,
          0.0471,  0.0502, -0.0496,  0.0482,  0.0363, -0.0798,  0.0357,  0.1164,
          0.0024,  0.0455, -0.1191, -0.1112, -0.0447,  0.1536, -0.0587, -0.0068,
         -0.0213,  0.1083, -0.1525]], device='cuda:0')
2022-04-10 11:57:41.701075 EDT | [gher-AntEnv-SAC-1000e-1000s-disc0.99-horizon1000_2022_04_10_11_56_30_0000--s-0] Epoch 1 finished
-------------------------------------------------  ---------------
replay_buffer/size                                  6000
trainer/QF1 Loss                                       0.553411
trainer/QF2 Loss                                       0.55547
trainer/Policy Loss                                   -9.42581
trainer/Q1 Predictions Mean                            4.00278
trainer/Q1 Predictions Std                             0.397348
trainer/Q1 Predictions Max                             5.25024
trainer/Q1 Predictions Min                             2.56
trainer/Q2 Predictions Mean                            4.00889
trainer/Q2 Predictions Std                             0.399194
trainer/Q2 Predictions Max                             5.27911
trainer/Q2 Predictions Min                             2.57188
trainer/Q Targets Mean                                 4.02395
trainer/Q Targets Std                                  0.667172
trainer/Q Targets Max                                  6.55136
trainer/Q Targets Min                                 -0.653406
trainer/Log Pis Mean                                  -5.44008
trainer/Log Pis Std                                    0.372709
trainer/Log Pis Max                                   -4.43901
trainer/Log Pis Min                                   -6.93049
trainer/Policy mu Mean                                -0.025775
trainer/Policy mu Std                                  0.0281748
trainer/Policy mu Max                                  0.0447175
trainer/Policy mu Min                                 -0.140748
trainer/Policy log std Mean                           -0.120065
trainer/Policy log std Std                             0.0226921
trainer/Policy log std Max                            -0.0635607
trainer/Policy log std Min                            -0.225418
trainer/Alpha                                          0.738429
trainer/Alpha Loss                                    -4.03511
exploration/num steps total                         3000
exploration/num paths total                           19
exploration/path length Mean                         166.667
exploration/path length Std                          245.715
exploration/path length Max                          711
exploration/path length Min                           20
exploration/Rewards Mean                              -0.371829
exploration/Rewards Std                                0.509298
exploration/Rewards Max                                1.74463
exploration/Rewards Min                               -2.07734
exploration/Returns Mean                             -61.9714
exploration/Returns Std                               91.4571
exploration/Returns Max                              -12.4635
exploration/Returns Min                             -265.206
exploration/Actions Mean                              -0.0141226
exploration/Actions Std                                0.599638
exploration/Actions Max                                0.997531
exploration/Actions Min                               -0.995271
exploration/Num Paths                                  6
exploration/Average Returns                          -61.9714
exploration/env_infos/final/reward_forward Mean       -0.136361
exploration/env_infos/final/reward_forward Std         1.2558
exploration/env_infos/final/reward_forward Max         1.87941
exploration/env_infos/final/reward_forward Min        -1.80456
exploration/env_infos/initial/reward_forward Mean     -0.0375383
exploration/env_infos/initial/reward_forward Std       0.250522
exploration/env_infos/initial/reward_forward Max       0.486016
exploration/env_infos/initial/reward_forward Min      -0.260567
exploration/env_infos/reward_forward Mean              0.0107156
exploration/env_infos/reward_forward Std               0.570442
exploration/env_infos/reward_forward Max               2.17116
exploration/env_infos/reward_forward Min              -2.69152
exploration/env_infos/final/reward_ctrl Mean          -1.48855
exploration/env_infos/final/reward_ctrl Std            0.53256
exploration/env_infos/final/reward_ctrl Max           -0.532754
exploration/env_infos/final/reward_ctrl Min           -2.34061
exploration/env_infos/initial/reward_ctrl Mean        -1.43584
exploration/env_infos/initial/reward_ctrl Std          0.305
exploration/env_infos/initial/reward_ctrl Max         -0.996595
exploration/env_infos/initial/reward_ctrl Min         -1.74023
exploration/env_infos/reward_ctrl Mean                -1.43906
exploration/env_infos/reward_ctrl Std                  0.428296
exploration/env_infos/reward_ctrl Max                 -0.338374
exploration/env_infos/reward_ctrl Min                 -3.07734
exploration/env_infos/final/reward_contact Mean        0
exploration/env_infos/final/reward_contact Std         0
exploration/env_infos/final/reward_contact Max        -0
exploration/env_infos/final/reward_contact Min        -0
exploration/env_infos/initial/reward_contact Mean      0
exploration/env_infos/initial/reward_contact Std       0
exploration/env_infos/initial/reward_contact Max      -0
exploration/env_infos/initial/reward_contact Min      -0
exploration/env_infos/reward_contact Mean              0
exploration/env_infos/reward_contact Std               0
exploration/env_infos/reward_contact Max              -0
exploration/env_infos/reward_contact Min              -0
exploration/env_infos/final/reward_survive Mean        1
exploration/env_infos/final/reward_survive Std         0
exploration/env_infos/final/reward_survive Max         1
exploration/env_infos/final/reward_survive Min         1
exploration/env_infos/initial/reward_survive Mean      1
exploration/env_infos/initial/reward_survive Std       0
exploration/env_infos/initial/reward_survive Max       1
exploration/env_infos/initial/reward_survive Min       1
exploration/env_infos/reward_survive Mean              1
exploration/env_infos/reward_survive Std               0
exploration/env_infos/reward_survive Max               1
exploration/env_infos/reward_survive Min               1
exploration/env_infos/final/torso_velocity Mean        0.573439
exploration/env_infos/final/torso_velocity Std         1.24177
exploration/env_infos/final/torso_velocity Max         3.18736
exploration/env_infos/final/torso_velocity Min        -1.80456
exploration/env_infos/initial/torso_velocity Mean      0.163511
exploration/env_infos/initial/torso_velocity Std       0.271137
exploration/env_infos/initial/torso_velocity Max       0.53092
exploration/env_infos/initial/torso_velocity Min      -0.260567
exploration/env_infos/torso_velocity Mean              0.0387661
exploration/env_infos/torso_velocity Std               0.594657
exploration/env_infos/torso_velocity Max               3.77018
exploration/env_infos/torso_velocity Min              -2.69445
evaluation/num steps total                         50000
evaluation/num paths total                            50
evaluation/path length Mean                         1000
evaluation/path length Std                             0
evaluation/path length Max                          1000
evaluation/path length Min                          1000
evaluation/Rewards Mean                                0.996776
evaluation/Rewards Std                                 0.0223376
evaluation/Rewards Max                                 2.33326
evaluation/Rewards Min                                 0.993198
evaluation/Returns Mean                              996.776
evaluation/Returns Std                                 1.57633
evaluation/Returns Max                              1001.75
evaluation/Returns Min                               995.089
evaluation/Actions Mean                               -0.0243206
evaluation/Actions Std                                 0.0212199
evaluation/Actions Max                                 0.0207843
evaluation/Actions Min                                -0.0719114
evaluation/Num Paths                                  25
evaluation/Average Returns                           996.776
evaluation/env_infos/final/reward_forward Mean         3.60724e-05
evaluation/env_infos/final/reward_forward Std          0.000533475
evaluation/env_infos/final/reward_forward Max          0.000805189
evaluation/env_infos/final/reward_forward Min         -0.00230427
evaluation/env_infos/initial/reward_forward Mean      -0.0128031
evaluation/env_infos/initial/reward_forward Std        0.118844
evaluation/env_infos/initial/reward_forward Max        0.178713
evaluation/env_infos/initial/reward_forward Min       -0.190033
evaluation/env_infos/reward_forward Mean               9.50646e-05
evaluation/env_infos/reward_forward Std                0.0434582
evaluation/env_infos/reward_forward Max                1.12647
evaluation/env_infos/reward_forward Min               -1.25621
evaluation/env_infos/final/reward_ctrl Mean           -0.00413517
evaluation/env_infos/final/reward_ctrl Std             0.000802636
evaluation/env_infos/final/reward_ctrl Max            -0.0025261
evaluation/env_infos/final/reward_ctrl Min            -0.00493173
evaluation/env_infos/initial/reward_ctrl Mean         -0.0026848
evaluation/env_infos/initial/reward_ctrl Std           0.000959871
evaluation/env_infos/initial/reward_ctrl Max          -0.00107099
evaluation/env_infos/initial/reward_ctrl Min          -0.00413658
evaluation/env_infos/reward_ctrl Mean                 -0.00416709
evaluation/env_infos/reward_ctrl Std                   0.000831078
evaluation/env_infos/reward_ctrl Max                  -0.00107099
evaluation/env_infos/reward_ctrl Min                  -0.00680157
evaluation/env_infos/final/reward_contact Mean         0
evaluation/env_infos/final/reward_contact Std          0
evaluation/env_infos/final/reward_contact Max         -0
evaluation/env_infos/final/reward_contact Min         -0
evaluation/env_infos/initial/reward_contact Mean       0
evaluation/env_infos/initial/reward_contact Std        0
evaluation/env_infos/initial/reward_contact Max       -0
evaluation/env_infos/initial/reward_contact Min       -0
evaluation/env_infos/reward_contact Mean               0
evaluation/env_infos/reward_contact Std                0
evaluation/env_infos/reward_contact Max               -0
evaluation/env_infos/reward_contact Min               -0
evaluation/env_infos/final/reward_survive Mean         1
evaluation/env_infos/final/reward_survive Std          0
evaluation/env_infos/final/reward_survive Max          1
evaluation/env_infos/final/reward_survive Min          1
evaluation/env_infos/initial/reward_survive Mean       1
evaluation/env_infos/initial/reward_survive Std        0
evaluation/env_infos/initial/reward_survive Max        1
evaluation/env_infos/initial/reward_survive Min        1
evaluation/env_infos/reward_survive Mean               1
evaluation/env_infos/reward_survive Std                0
evaluation/env_infos/reward_survive Max                1
evaluation/env_infos/reward_survive Min                1
evaluation/env_infos/final/torso_velocity Mean         1.52103e-05
evaluation/env_infos/final/torso_velocity Std          0.00055033
evaluation/env_infos/final/torso_velocity Max          0.00367248
evaluation/env_infos/final/torso_velocity Min         -0.00230427
evaluation/env_infos/initial/torso_velocity Mean       0.149766
evaluation/env_infos/initial/torso_velocity Std        0.229148
evaluation/env_infos/initial/torso_velocity Max        0.575205
evaluation/env_infos/initial/torso_velocity Min       -0.190033
evaluation/env_infos/torso_velocity Mean              -0.00154741
evaluation/env_infos/torso_velocity Std                0.0500405
evaluation/env_infos/torso_velocity Max                1.32506
evaluation/env_infos/torso_velocity Min               -1.81942
time/data storing (s)                                  0.393828
time/evaluation sampling (s)                          27.6096
time/exploration sampling (s)                          1.21819
time/logging (s)                                       0.0922143
time/saving (s)                                        0.177662
time/training (s)                                      0.752717
time/epoch (s)                                        30.2442
time/total (s)                                        80.9583
Epoch                                                  1
-------------------------------------------------  ---------------
Self.relabel is : True
Latents is : <class 'numpy.ndarray'>, its shape is : (2, 1), print for latent : [[2.42]
 [2.58]]
obs is : <class 'numpy.ndarray'>, its shape is : (27,), print for obs : [0.65 1.00 0.00 -0.01 -0.03 0.07 0.01 -0.05 -0.01 -0.09 0.03 -0.05 0.06
 -0.01 -0.07 0.12 0.18 -0.12 0.00 -0.02 0.01 -0.05 -0.10 -0.13 0.01 -0.03
 -0.18]
AFTER RESHAPE
latent is : <class 'torch.Tensor'>, its shape is : torch.Size([2, 1]), print for latent : tensor([[2.4163],
        [2.5773]], device='cuda:0')
obs is : <class 'torch.Tensor'>, its shape is : torch.Size([2, 27]), print for obs : tensor([[ 6.5080e-01,  9.9948e-01,  4.4368e-03, -1.0150e-02, -3.0143e-02,
          7.4132e-02,  1.2799e-02, -4.9403e-02, -1.0211e-02, -8.6598e-02,
          2.7643e-02, -5.2701e-02,  5.7394e-02, -1.3740e-02, -7.4493e-02,
          1.2350e-01,  1.8446e-01, -1.2267e-01,  8.7713e-05, -1.5875e-02,
          1.2643e-02, -4.8244e-02, -1.0449e-01, -1.3450e-01,  6.0666e-03,
         -2.7364e-02, -1.8044e-01],
        [ 6.5080e-01,  9.9948e-01,  4.4368e-03, -1.0150e-02, -3.0143e-02,
          7.4132e-02,  1.2799e-02, -4.9403e-02, -1.0211e-02, -8.6598e-02,
          2.7643e-02, -5.2701e-02,  5.7394e-02, -1.3740e-02, -7.4493e-02,
          1.2350e-01,  1.8446e-01, -1.2267e-01,  8.7713e-05, -1.5875e-02,
          1.2643e-02, -4.8244e-02, -1.0449e-01, -1.3450e-01,  6.0666e-03,
         -2.7364e-02, -1.8044e-01]], device='cuda:0')
2022-04-10 11:58:12.057145 EDT | [gher-AntEnv-SAC-1000e-1000s-disc0.99-horizon1000_2022_04_10_11_56_30_0000--s-0] Epoch 2 finished
-------------------------------------------------  ---------------
replay_buffer/size                                  8000
trainer/QF1 Loss                                       0.44552
trainer/QF2 Loss                                       0.447115
trainer/Policy Loss                                   -9.13942
trainer/Q1 Predictions Mean                            3.71031
trainer/Q1 Predictions Std                             0.356806
trainer/Q1 Predictions Max                             5.22498
trainer/Q1 Predictions Min                             2.43015
trainer/Q2 Predictions Mean                            3.70509
trainer/Q2 Predictions Std                             0.355772
trainer/Q2 Predictions Max                             5.25898
trainer/Q2 Predictions Min                             2.43085
trainer/Q Targets Mean                                 3.86912
trainer/Q Targets Std                                  0.670585
trainer/Q Targets Max                                  6.71462
trainer/Q Targets Min                                 -0.653406
trainer/Log Pis Mean                                  -5.43987
trainer/Log Pis Std                                    0.324857
trainer/Log Pis Max                                   -4.67356
trainer/Log Pis Min                                   -6.78109
trainer/Policy mu Mean                                -0.00650355
trainer/Policy mu Std                                  0.0317397
trainer/Policy mu Max                                  0.100389
trainer/Policy mu Min                                 -0.124147
trainer/Policy log std Mean                           -0.119195
trainer/Policy log std Std                             0.0236086
trainer/Policy log std Max                            -0.0617614
trainer/Policy log std Min                            -0.232322
trainer/Alpha                                          0.547015
trainer/Alpha Loss                                    -8.06769
exploration/num steps total                         4000
exploration/num paths total                           20
exploration/path length Mean                        1000
exploration/path length Std                            0
exploration/path length Max                         1000
exploration/path length Min                         1000
exploration/Rewards Mean                              -0.356142
exploration/Rewards Std                                0.453348
exploration/Rewards Max                                1.44664
exploration/Rewards Min                               -1.73151
exploration/Returns Mean                            -356.142
exploration/Returns Std                                0
exploration/Returns Max                             -356.142
exploration/Returns Min                             -356.142
exploration/Actions Mean                              -0.00968802
exploration/Actions Std                                0.590719
exploration/Actions Max                                0.997633
exploration/Actions Min                               -0.995458
exploration/Num Paths                                  1
exploration/Average Returns                         -356.142
exploration/env_infos/final/reward_forward Mean        0.122881
exploration/env_infos/final/reward_forward Std         0
exploration/env_infos/final/reward_forward Max         0.122881
exploration/env_infos/final/reward_forward Min         0.122881
exploration/env_infos/initial/reward_forward Mean      0.0331633
exploration/env_infos/initial/reward_forward Std       0
exploration/env_infos/initial/reward_forward Max       0.0331633
exploration/env_infos/initial/reward_forward Min       0.0331633
exploration/env_infos/reward_forward Mean             -0.0309306
exploration/env_infos/reward_forward Std               0.404563
exploration/env_infos/reward_forward Max               1.12847
exploration/env_infos/reward_forward Min              -1.73017
exploration/env_infos/final/reward_ctrl Mean          -2.0926
exploration/env_infos/final/reward_ctrl Std            0
exploration/env_infos/final/reward_ctrl Max           -2.0926
exploration/env_infos/final/reward_ctrl Min           -2.0926
exploration/env_infos/initial/reward_ctrl Mean        -1.36151
exploration/env_infos/initial/reward_ctrl Std          0
exploration/env_infos/initial/reward_ctrl Max         -1.36151
exploration/env_infos/initial/reward_ctrl Min         -1.36151
exploration/env_infos/reward_ctrl Mean                -1.39617
exploration/env_infos/reward_ctrl Std                  0.426721
exploration/env_infos/reward_ctrl Max                 -0.137313
exploration/env_infos/reward_ctrl Min                 -2.73151
exploration/env_infos/final/reward_contact Mean        0
exploration/env_infos/final/reward_contact Std         0
exploration/env_infos/final/reward_contact Max        -0
exploration/env_infos/final/reward_contact Min        -0
exploration/env_infos/initial/reward_contact Mean      0
exploration/env_infos/initial/reward_contact Std       0
exploration/env_infos/initial/reward_contact Max      -0
exploration/env_infos/initial/reward_contact Min      -0
exploration/env_infos/reward_contact Mean              0
exploration/env_infos/reward_contact Std               0
exploration/env_infos/reward_contact Max              -0
exploration/env_infos/reward_contact Min              -0
exploration/env_infos/final/reward_survive Mean        1
exploration/env_infos/final/reward_survive Std         0
exploration/env_infos/final/reward_survive Max         1
exploration/env_infos/final/reward_survive Min         1
exploration/env_infos/initial/reward_survive Mean      1
exploration/env_infos/initial/reward_survive Std       0
exploration/env_infos/initial/reward_survive Max       1
exploration/env_infos/initial/reward_survive Min       1
exploration/env_infos/reward_survive Mean              1
exploration/env_infos/reward_survive Std               0
exploration/env_infos/reward_survive Max               1
exploration/env_infos/reward_survive Min               1
exploration/env_infos/final/torso_velocity Mean       -0.0298382
exploration/env_infos/final/torso_velocity Std         0.12485
exploration/env_infos/final/torso_velocity Max         0.122881
exploration/env_infos/final/torso_velocity Min        -0.182937
exploration/env_infos/initial/torso_velocity Mean      0.199822
exploration/env_infos/initial/torso_velocity Std       0.262127
exploration/env_infos/initial/torso_velocity Max       0.569917
exploration/env_infos/initial/torso_velocity Min      -0.00361363
exploration/env_infos/torso_velocity Mean             -0.00705325
exploration/env_infos/torso_velocity Std               0.368016
exploration/env_infos/torso_velocity Max               2.86077
exploration/env_infos/torso_velocity Min              -2.51344
evaluation/num steps total                         75000
evaluation/num paths total                            75
evaluation/path length Mean                         1000
evaluation/path length Std                             0
evaluation/path length Max                          1000
evaluation/path length Min                          1000
evaluation/Rewards Mean                                0.99825
evaluation/Rewards Std                                 0.023936
evaluation/Rewards Max                                 2.40701
evaluation/Rewards Min                                 0.991403
evaluation/Returns Mean                              998.25
evaluation/Returns Std                                 1.20778
evaluation/Returns Max                              1001.79
evaluation/Returns Min                               997.273
evaluation/Actions Mean                               -0.008522
evaluation/Actions Std                                 0.0240713
evaluation/Actions Max                                 0.0662601
evaluation/Actions Min                                -0.0997996
evaluation/Num Paths                                  25
evaluation/Average Returns                           998.25
evaluation/env_infos/final/reward_forward Mean        -0.000164973
evaluation/env_infos/final/reward_forward Std          0.000755747
evaluation/env_infos/final/reward_forward Max          6.05767e-07
evaluation/env_infos/final/reward_forward Min         -0.00385885
evaluation/env_infos/initial/reward_forward Mean       0.00465579
evaluation/env_infos/initial/reward_forward Std        0.135919
evaluation/env_infos/initial/reward_forward Max        0.288541
evaluation/env_infos/initial/reward_forward Min       -0.335836
evaluation/env_infos/reward_forward Mean               0.0013045
evaluation/env_infos/reward_forward Std                0.0562328
evaluation/env_infos/reward_forward Max                1.47686
evaluation/env_infos/reward_forward Min               -0.981523
evaluation/env_infos/final/reward_ctrl Mean           -0.00258976
evaluation/env_infos/final/reward_ctrl Std             8.00957e-05
evaluation/env_infos/final/reward_ctrl Max            -0.00242112
evaluation/env_infos/final/reward_ctrl Min            -0.00271152
evaluation/env_infos/initial/reward_ctrl Mean         -0.00233071
evaluation/env_infos/initial/reward_ctrl Std           0.000265455
evaluation/env_infos/initial/reward_ctrl Max          -0.00174112
evaluation/env_infos/initial/reward_ctrl Min          -0.00274107
evaluation/env_infos/reward_ctrl Mean                 -0.00260821
evaluation/env_infos/reward_ctrl Std                   0.000240681
evaluation/env_infos/reward_ctrl Max                  -0.00151468
evaluation/env_infos/reward_ctrl Min                  -0.0085968
evaluation/env_infos/final/reward_contact Mean         0
evaluation/env_infos/final/reward_contact Std          0
evaluation/env_infos/final/reward_contact Max         -0
evaluation/env_infos/final/reward_contact Min         -0
evaluation/env_infos/initial/reward_contact Mean       0
evaluation/env_infos/initial/reward_contact Std        0
evaluation/env_infos/initial/reward_contact Max       -0
evaluation/env_infos/initial/reward_contact Min       -0
evaluation/env_infos/reward_contact Mean               0
evaluation/env_infos/reward_contact Std                0
evaluation/env_infos/reward_contact Max               -0
evaluation/env_infos/reward_contact Min               -0
evaluation/env_infos/final/reward_survive Mean         1
evaluation/env_infos/final/reward_survive Std          0
evaluation/env_infos/final/reward_survive Max          1
evaluation/env_infos/final/reward_survive Min          1
evaluation/env_infos/initial/reward_survive Mean       1
evaluation/env_infos/initial/reward_survive Std        0
evaluation/env_infos/initial/reward_survive Max        1
evaluation/env_infos/initial/reward_survive Min        1
evaluation/env_infos/reward_survive Mean               1
evaluation/env_infos/reward_survive Std                0
evaluation/env_infos/reward_survive Max                1
evaluation/env_infos/reward_survive Min                1
evaluation/env_infos/final/torso_velocity Mean         6.75562e-05
evaluation/env_infos/final/torso_velocity Std          0.00140149
evaluation/env_infos/final/torso_velocity Max          0.011364
evaluation/env_infos/final/torso_velocity Min         -0.00385885
evaluation/env_infos/initial/torso_velocity Mean       0.154306
evaluation/env_infos/initial/torso_velocity Std        0.248945
evaluation/env_infos/initial/torso_velocity Max        0.599293
evaluation/env_infos/initial/torso_velocity Min       -0.335836
evaluation/env_infos/torso_velocity Mean              -0.000769034
evaluation/env_infos/torso_velocity Std                0.0559864
evaluation/env_infos/torso_velocity Max                1.47686
evaluation/env_infos/torso_velocity Min               -1.96907
time/data storing (s)                                  0.455645
time/evaluation sampling (s)                          27.5482
time/exploration sampling (s)                          1.22276
time/logging (s)                                       0.0900997
time/saving (s)                                        0.225916
time/training (s)                                      0.75243
time/epoch (s)                                        30.2951
time/total (s)                                       111.312
Epoch                                                  2
-------------------------------------------------  ---------------
slurmstepd: error: *** JOB 17625859 ON gv006 CANCELLED AT 2022-04-10T11:58:33 ***
